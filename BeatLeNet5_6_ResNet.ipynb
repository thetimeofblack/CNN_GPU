{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# import some keras and basic module \n",
    "\n",
    "from __future__ import print_function \n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# data set cifar 10 \n",
    "from tensorflow.keras.datasets import cifar10 \n",
    "\n",
    "# basic preprocesssing for image data \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# construct neural network \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten \n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras import models \n",
    "import os \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf \n",
    "\n",
    "config = tf.ConfigProto()\n",
    "tf.enable_eager_execution(config=config)\n",
    "\n",
    "from fmp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## basic parameters \n",
    "batch_size = 40 \n",
    "num_classes = 10 \n",
    "num_epochs = 300 \n",
    "is_data_augmentation = True \n",
    "model_dir = 'models'\n",
    "model_filename = 'model_BeatLeNet5_6_ResNet.h'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Network.summary of <tensorflow.python.keras.engine.training.Model object at 0x0000023CC942E708>>\n"
     ]
    }
   ],
   "source": [
    "def residual_network(x):\n",
    "    \n",
    "    def add_common_layers(y):\n",
    "        y = layers.BatchNormalization()(y)\n",
    "        y = layers.LeakyReLU()(y)\n",
    "        \n",
    "        return y \n",
    "    def grouped_convolution(y,nb_channels,_strides):\n",
    "        if cardinality == 1:\n",
    "            return layers.Conv2D(nb_channels, kernel_size=(3,3), strides=_strides, padding='same')(y)\n",
    "        assert not nb_channels % cardinality \n",
    "        _d = nb_channels // cardinality \n",
    "        \n",
    "        \n",
    "        groups = []\n",
    "        for j in range(cardinality):\n",
    "            group = layers.Lambda(lambda z: z[:, :, :, j* _d:j * _d + _d])(y)\n",
    "            groups.append(layers.Conv2D(_d,kernel_size=(3,3),strides = _strides, padding = 'same')(group))\n",
    "            \n",
    "        y = layers.concatenate(groups)\n",
    "        \n",
    "        return y \n",
    "    \n",
    "    def residual_block(y, nb_channels_in,nb_channels_out,_strides = (1,1), _project_shortcut= False):\n",
    "        \"\"\"\n",
    "        Our network consists of a stack of residual blocks. These blocks have the same topology, \n",
    "        and are subject to two simple rules:\n",
    "        \n",
    "        - If producing spatial maps of the same size, the blocks share the same \n",
    "        \n",
    "        \"\"\"\n",
    "        shortcut = y \n",
    "        \n",
    "        y = layers.Conv2D(nb_channels_in, kernel_size=(1,1) , strides=(1,1) , padding='same')(y)\n",
    "        y = add_common_layers(y)\n",
    "        \n",
    "        y = grouped_convolution(y,nb_channels_in,_strides=_strides)\n",
    "        y = add_common_layers(y)\n",
    "        \n",
    "        y = layers.Conv2D(nb_channels_out,kernel_size=(1,1),strides=(1,1), padding='same')(y)\n",
    "        \n",
    "        y = layers.BatchNormalization()(y)\n",
    "        \n",
    "        if _project_shortcut or _strides != (1, 1):\n",
    "            \n",
    "            shortcut = layers.Conv2D(nb_channels_out, kernel_size=(1,1), strides=_strides, padding='same')(shortcut)\n",
    "            shortcut = layers.BatchNormalization()(shortcut)\n",
    "            \n",
    "        y = layers.add([shortcut, y])\n",
    "        \n",
    "        y = layers.LeakyReLU()(y)\n",
    "        \n",
    "        return y \n",
    "    \n",
    "    x = layers.Conv2D(32,kernel_size=(5,5), strides=(1,1), padding='same')(x)\n",
    "    x = add_common_layers(x)\n",
    "    \n",
    "    x = layers.MaxPool2D(pool_size=(2,2), strides=(1,1), padding='same')(x)\n",
    "    for i in range(3):\n",
    "        project_shortcut = True if i == 0 else False \n",
    "        x = residual_block(x,16,32,_project_shortcut=project_shortcut)\n",
    "        \n",
    "        \n",
    "    for i in range(4): \n",
    "        strides = (2,2) if i == 0 else (1,1)\n",
    "        x = residual_block(x, 32, 64, _strides=strides)\n",
    "        \n",
    "    for i in range(6):\n",
    "        strides = (2,2) if i==0 else (1,1)\n",
    "        x = residual_block(x, 64, 128, _strides=strides)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(10)(x)\n",
    "    \n",
    "    return x \n",
    "img_height = 32\n",
    "img_width = 32 \n",
    "img_channels = 3 \n",
    "cardinality = 2\n",
    "image_tensor = layers.Input(shape=(img_height, img_width, img_channels))\n",
    "network_output = residual_network(image_tensor)\n",
    "\n",
    "cnn_model = models.Model(inputs=[image_tensor], outputs=[network_output])\n",
    "\n",
    "print(cnn_model.summary)\n",
    "#plot_model(cnn_model, show_shapes=True,to_file='cnn_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "(10000, 10)\n",
      "the shape of training data set is:  (50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#read data and split data into train and test set\n",
    "\n",
    "(train_set,train_label),(test_set,test_label) = cifar10.load_data() \n",
    "\n",
    "# Convert class label to binary vector \n",
    "train_label = keras.utils.to_categorical(train_label,num_classes)\n",
    "test_label  = keras.utils.to_categorical(test_label,num_classes) \n",
    "print(train_label.shape)\n",
    "print(test_label.shape)\n",
    "print('the shape of training data set is: ',train_set.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "(50000, 32, 32, 3)\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/300\n",
      "50000/50000 [==============================] - 94s 2ms/sample - loss: 8.1907 - acc: 0.1115 - val_loss: 7.8846 - val_acc: 0.1056\n",
      "Epoch 2/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 8.1452 - acc: 0.1121 - val_loss: 8.7704 - val_acc: 0.1168\n",
      "Epoch 3/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 8.3482 - acc: 0.1151 - val_loss: 8.2451 - val_acc: 0.1070\n",
      "Epoch 4/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 8.2435 - acc: 0.1109 - val_loss: 8.0909 - val_acc: 0.1128\n",
      "Epoch 5/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 8.0216 - acc: 0.1189 - val_loss: 7.9105 - val_acc: 0.1129\n",
      "Epoch 6/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.8884 - acc: 0.1208 - val_loss: 7.6725 - val_acc: 0.1136\n",
      "Epoch 7/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.9477 - acc: 0.1306 - val_loss: 7.6670 - val_acc: 0.1343\n",
      "Epoch 8/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 7.8719 - acc: 0.1300 - val_loss: 7.7469 - val_acc: 0.1151\n",
      "Epoch 9/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.9373 - acc: 0.1144 - val_loss: 8.3244 - val_acc: 0.0825\n",
      "Epoch 10/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.0032 - acc: 0.1087 - val_loss: 7.9770 - val_acc: 0.1363\n",
      "Epoch 11/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.8873 - acc: 0.1171 - val_loss: 8.2076 - val_acc: 0.1161\n",
      "Epoch 12/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.9479 - acc: 0.1265 - val_loss: 7.8769 - val_acc: 0.1318\n",
      "Epoch 13/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.7959 - acc: 0.1279 - val_loss: 8.2136 - val_acc: 0.1270\n",
      "Epoch 14/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.7994 - acc: 0.1218 - val_loss: 7.6001 - val_acc: 0.1119\n",
      "Epoch 15/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.7418 - acc: 0.1167 - val_loss: 7.9058 - val_acc: 0.1117\n",
      "Epoch 16/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.3246 - acc: 0.1105 - val_loss: 8.0530 - val_acc: 0.0957\n",
      "Epoch 17/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.0685 - acc: 0.1021 - val_loss: 8.0305 - val_acc: 0.1091\n",
      "Epoch 18/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.0076 - acc: 0.1211 - val_loss: 8.0679 - val_acc: 0.1240\n",
      "Epoch 19/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.1367 - acc: 0.1352 - val_loss: 8.2774 - val_acc: 0.1341\n",
      "Epoch 20/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.9695 - acc: 0.1238 - val_loss: 8.4820 - val_acc: 0.1094\n",
      "Epoch 21/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.7545 - acc: 0.1180 - val_loss: 8.3844 - val_acc: 0.1130\n",
      "Epoch 22/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 7.7905 - acc: 0.1280 - val_loss: 8.4219 - val_acc: 0.1198\n",
      "Epoch 23/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.7769 - acc: 0.1238 - val_loss: 8.0702 - val_acc: 0.1330\n",
      "Epoch 24/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.9124 - acc: 0.1145 - val_loss: 7.8190 - val_acc: 0.0944\n",
      "Epoch 25/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.9203 - acc: 0.1103 - val_loss: 7.5258 - val_acc: 0.1051\n",
      "Epoch 26/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.0039 - acc: 0.1147 - val_loss: 7.8318 - val_acc: 0.1187\n",
      "Epoch 27/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.9018 - acc: 0.1138 - val_loss: 8.1025 - val_acc: 0.1181\n",
      "Epoch 28/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.0657 - acc: 0.1191 - val_loss: 8.0871 - val_acc: 0.1075\n",
      "Epoch 29/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.2945 - acc: 0.1248 - val_loss: 8.3330 - val_acc: 0.1358\n",
      "Epoch 30/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.2198 - acc: 0.1301 - val_loss: 8.4119 - val_acc: 0.1286\n",
      "Epoch 31/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 7.9917 - acc: 0.1147 - val_loss: 7.9761 - val_acc: 0.1051\n",
      "Epoch 32/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.0174 - acc: 0.1115 - val_loss: 7.9636 - val_acc: 0.1145\n",
      "Epoch 33/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.9051 - acc: 0.1112 - val_loss: 7.5795 - val_acc: 0.0957\n",
      "Epoch 34/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.9589 - acc: 0.1035 - val_loss: 8.1463 - val_acc: 0.1069\n",
      "Epoch 35/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.0313 - acc: 0.1116 - val_loss: 8.3675 - val_acc: 0.1214\n",
      "Epoch 36/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.9066 - acc: 0.1093 - val_loss: 7.8691 - val_acc: 0.1131\n",
      "Epoch 37/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.9896 - acc: 0.1260 - val_loss: 8.1232 - val_acc: 0.1268\n",
      "Epoch 38/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.8973 - acc: 0.1258 - val_loss: 7.8011 - val_acc: 0.1326\n",
      "Epoch 39/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.0045 - acc: 0.1295 - val_loss: 8.1702 - val_acc: 0.1392\n",
      "Epoch 40/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.1378 - acc: 0.1392 - val_loss: 8.2629 - val_acc: 0.1285\n",
      "Epoch 41/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.2264 - acc: 0.1331 - val_loss: 8.2158 - val_acc: 0.1407\n",
      "Epoch 42/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.0002 - acc: 0.1335 - val_loss: 7.9243 - val_acc: 0.1359\n",
      "Epoch 43/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 8.0637 - acc: 0.1304 - val_loss: 7.9167 - val_acc: 0.1346\n",
      "Epoch 44/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.2007 - acc: 0.1155 - val_loss: 7.9566 - val_acc: 0.1204\n",
      "Epoch 45/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.0107 - acc: 0.1055 - val_loss: 8.3082 - val_acc: 0.1006\n",
      "Epoch 46/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.0005 - acc: 0.1117 - val_loss: 8.4337 - val_acc: 0.1207\n",
      "Epoch 47/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.9930 - acc: 0.1103 - val_loss: 7.6666 - val_acc: 0.1189\n",
      "Epoch 48/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.0250 - acc: 0.1143 - val_loss: 8.1776 - val_acc: 0.1286\n",
      "Epoch 49/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 7.8991 - acc: 0.1275 - val_loss: 8.4082 - val_acc: 0.1371\n",
      "Epoch 50/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.3153 - acc: 0.1323 - val_loss: 8.2025 - val_acc: 0.1289\n",
      "Epoch 51/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.3479 - acc: 0.1442 - val_loss: 8.1786 - val_acc: 0.1283\n",
      "Epoch 52/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.2914 - acc: 0.1354 - val_loss: 8.0150 - val_acc: 0.1307\n",
      "Epoch 53/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.1821 - acc: 0.1458 - val_loss: 8.3025 - val_acc: 0.1522\n",
      "Epoch 54/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.2533 - acc: 0.1411 - val_loss: 8.1278 - val_acc: 0.1312\n",
      "Epoch 55/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.0250 - acc: 0.1231 - val_loss: 8.1504 - val_acc: 0.1355\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.1009 - acc: 0.1363 - val_loss: 7.8451 - val_acc: 0.1227\n",
      "Epoch 57/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.1176 - acc: 0.1248 - val_loss: 8.0151 - val_acc: 0.1160\n",
      "Epoch 58/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.1510 - acc: 0.1190 - val_loss: 8.3683 - val_acc: 0.1193\n",
      "Epoch 59/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.1786 - acc: 0.1127 - val_loss: 9.0768 - val_acc: 0.1104\n",
      "Epoch 60/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.0886 - acc: 0.1224 - val_loss: 8.0827 - val_acc: 0.1112\n",
      "Epoch 61/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 8.0188 - acc: 0.1073 - val_loss: 7.8545 - val_acc: 0.0867\n",
      "Epoch 62/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 3.7318 - acc: 0.1007 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 63/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 64/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 65/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 66/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 67/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 68/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 69/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 70/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 71/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 72/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 73/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 74/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 75/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 76/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 77/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 78/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 79/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 80/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 81/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 82/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 83/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 84/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 85/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 86/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 87/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 88/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 89/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 90/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 91/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 92/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 93/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 94/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 95/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 96/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 97/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 98/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 99/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 100/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 101/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 102/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 103/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 104/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 105/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 106/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 107/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 108/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 109/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 110/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 112/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 113/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 114/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 115/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 116/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 117/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 118/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 119/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 120/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 121/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 122/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 123/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 124/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 125/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 126/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 127/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 128/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 129/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 130/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 131/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 132/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 133/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 134/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 135/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 136/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 137/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 138/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 139/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 140/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 141/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 142/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 143/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 144/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 145/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 146/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 147/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 148/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 149/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 150/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 151/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 152/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 153/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 154/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 155/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 156/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 157/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 158/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 159/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 160/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 161/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 162/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 163/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 164/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 165/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 166/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 167/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 168/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 169/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 170/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 171/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 172/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 173/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 174/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 175/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 176/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 177/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 178/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 179/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 180/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 181/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 182/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 183/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 184/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 185/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 186/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 187/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 188/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 189/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 190/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 191/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 192/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 193/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 194/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 195/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 196/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 197/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 198/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 199/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 200/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 201/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 202/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 203/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 204/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 205/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 206/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 207/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 208/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 209/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 210/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 211/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 212/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 213/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 214/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 215/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 216/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 217/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 218/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 219/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 221/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 222/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 223/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 224/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 225/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 226/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 227/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 228/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 229/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 230/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 231/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 232/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 233/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 234/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 235/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 236/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 237/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 238/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 239/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 240/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 241/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 242/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 243/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 244/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 245/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 246/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 247/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 248/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 249/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 250/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 251/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 252/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 253/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 254/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 255/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 256/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 257/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 258/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 259/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 260/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 261/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 262/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 263/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 264/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 265/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 266/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 267/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 268/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 269/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 270/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 271/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 272/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 273/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 274/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 275/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 276/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 277/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 278/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 279/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 280/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 281/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 282/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 283/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 284/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 285/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 286/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 287/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 288/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 289/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 290/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 291/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 292/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 293/300\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 294/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 295/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 296/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 297/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 298/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 299/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "Epoch 300/300\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.1921e-07 - acc: 0.1000 - val_loss: 1.1921e-07 - val_acc: 0.1000\n",
      "CNN Model saved at models\\model_BeatLeNet5_6_ResNet.h \n",
      "10000/10000 [==============================] - 8s 763us/sample - loss: 1.1921e-07 - acc: 0.1000\n",
      "50000/50000 [==============================] - 28s 558us/sample - loss: 1.1921e-07 - acc: 0.1000\n",
      "Train loss:  1.1920930376163597e-07\n",
      "Trian metric:  0.1\n",
      "Test loss:  1.1920930376163597e-07\n",
      "Test accuracy: 0.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# initialization of optimizer \n",
    "opt = keras.optimizers.Adadelta(learning_rate=0.1, rho=0.95)\n",
    "\n",
    "# train the model by optimizer\n",
    "cnn_model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = opt,\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "train_set = train_set.astype('float32')\n",
    "test_set = test_set.astype('float32') \n",
    "\n",
    "train_set /= 255 \n",
    "test_set /= 255 \n",
    "\n",
    "if not is_data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    cnn_history = cnn_model.fit(train_set, train_label,\n",
    "              batch_size=batch_size,\n",
    "              epochs=num_epochs,\n",
    "              validation_data=(test_set, test_label),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "     \n",
    "    \n",
    "    # set parameter for data augmentation \n",
    "    data_transform_parameters = {\n",
    "                                \"rotation_range\": 15,\n",
    "                                \"width_shift_range\":0.1,\n",
    "                                \"height_shift_range\":0.1,\n",
    "                                \"horizontal_flip\":True\n",
    "                                }\n",
    "    \n",
    "    # get object of augmentation data generator \n",
    "    augment_data_set_generator = ImageDataGenerator(data_transform_parameters)    \n",
    "    \n",
    "    \n",
    "    # get augmented data set \n",
    "    \n",
    "    augment_train_set = augment_data_set_generator.apply_transform(train_set,data_transform_parameters)\n",
    "    print(augment_train_set.shape)\n",
    "  \n",
    "    \n",
    "    # Limit GPU device to the first GPU \n",
    "    #gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    #if gpus:\n",
    "      # Restrict TensorFlow to only use the first GPU\n",
    "    #  try:\n",
    "    #    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    #    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    #    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    #  except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "    #    print(e)\n",
    "        \n",
    "        \n",
    "    # train model by GPU \n",
    "    with tf.device('/device:GPU:0'):\n",
    "        cnn_history = cnn_model.fit(augment_train_set, train_label,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=num_epochs,\n",
    "                  validation_data=(test_set, test_label),\n",
    "                  shuffle=True)\n",
    "\n",
    "# save model and weights \n",
    "if not os.path.isdir(model_dir): \n",
    "    os.makedirs(model_dir) \n",
    "model_path = os.path.join(model_dir,model_filename)\n",
    "cnn_model.save(model_path)\n",
    "print(\"CNN Model saved at %s \" % model_path)\n",
    "\n",
    "# Score trained model \n",
    "\n",
    "test_loss_value, test_metric_value = cnn_model.evaluate(test_set,test_label,verbose =1 )\n",
    "train_loss_value, train_metric_value = cnn_model.evaluate(train_set,train_label,verbose =1)\n",
    "\n",
    "\n",
    "print(\"Train loss: \", train_loss_value) \n",
    "print(\"Trian metric: \", train_metric_value)\n",
    "\n",
    "print(\"Test loss: \", test_loss_value)\n",
    "print(\"Test accuracy:\", test_metric_value)\n",
    "# print(cnn_history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'test loss and test accuracy')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# get history data\n",
    "epoth_x = np.linspace(0, 10, num_epochs, endpoint=True)\n",
    "train_loss = cnn_history.history['loss']\n",
    "train_accuracy = cnn_history.history['acc']\n",
    "test_loss = cnn_history.history['val_loss']\n",
    "test_accuracy = cnn_history.history['val_acc']\n",
    "\n",
    "# plot train loss and accuracy\n",
    "plt.figure() \n",
    "plt.plot(epoth_x, train_loss,label = 'train loss')\n",
    "plt.plot(epoth_x,train_accuracy,label = 'train accuracy')\n",
    "plt.title(\"train loss and train accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# plot test loss and accuracy\n",
    "plt.figure() \n",
    "plt.plot(epoth_x, test_loss, label = 'test loss')\n",
    "plt.plot(epoth_x,test_accuracy, label = 'test accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"test loss and test accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
