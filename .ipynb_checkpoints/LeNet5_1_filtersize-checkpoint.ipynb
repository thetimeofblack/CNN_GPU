{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# import some keras and basic module \n",
    "\n",
    "from __future__ import print_function \n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "# data set cifar 10 \n",
    "from tensorflow.keras.datasets import cifar10 \n",
    "\n",
    "# basic preprocesssing for image data \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# construct neural network \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten \n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import os \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "config = tf.ConfigProto()\n",
    "tf.enable_eager_execution(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## basic parameters \n",
    "batch_size = 32 \n",
    "num_classes = 10 \n",
    "num_epochs = 200\n",
    "is_data_augmentation = False \n",
    "num_predictions = 20 \n",
    "model_dir = 'models'\n",
    "model_filename = 'keras_cifar10_LeNet5_1_filtersize.h1'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of training data set is:  (50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#read data and split data into train and test set\n",
    "\n",
    "(train_set,train_label),(test_set,test_label) = cifar10.load_data() \n",
    "\n",
    "print('the shape of training data set is: ',train_set.shape) \n",
    "\n",
    "# print number of train and test samples \n",
    "\n",
    "# train samples 50000\n",
    "#print(train_set.shape[0] , 'train samples') \n",
    "\n",
    "# test samples 10000\n",
    "#print(test_set.shape[0] , 'test samples') \n",
    "\n",
    "#print(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Convert class label to binary vector \n",
    "train_label = keras.utils.to_categorical(train_label,num_classes)\n",
    "test_label  = keras.utils.to_categorical(test_label,num_classes) \n",
    "print(train_label.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the code input for Conv2D \n",
    "```\n",
    "tf.keras.layers.Conv2D(\n",
    "    filters, kernel_size, strides=(1, 1), padding='valid', data_format=None,\n",
    "    dilation_rate=(1, 1), activation=None, use_bias=True,\n",
    "    kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
    "    kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None,\n",
    "    kernel_constraint=None, bias_constraint=None, **kwargs\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the model \n",
    "\n",
    "cnn_model = Sequential() \n",
    "\n",
    "\n",
    "# convolutional layer stride 1 no padding nfilters = 6 input_shape = 32*32*3\n",
    "# acitvation = softmax\n",
    "cnn_model.add(Conv2D(20,(5,5),padding='valid',input_shape=train_set.shape[1:], ))\n",
    "cnn_model.add(Activation('relu'))\n",
    "\n",
    "# max-pooling layer window size 2*2\n",
    "cnn_model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# convolutional layer stride 1 no padding nfilters = 6 input_shape = 14*14*6\n",
    "# activation = softmax\n",
    "cnn_model.add(Conv2D(40,(5,5),padding ='valid'))\n",
    "cnn_model.add(Activation('relu'))\n",
    "\n",
    "# max-pooling layer window size 2*2\n",
    "cnn_model.add(MaxPooling2D(pool_size =(2,2) ))\n",
    "\n",
    "# flatten 2d to 1d \n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "\n",
    "# full connected layer nfilters = 120 \n",
    "\n",
    "cnn_model.add(Dense(150,activation = 'relu' )) \n",
    "\n",
    "# full connected layer nfilters = 84 \n",
    "cnn_model.add(Dense(90, activation = 'relu'))\n",
    "\n",
    "# last full connected layer nfilters = 10 \n",
    "cnn_model.add(Dense(10 , activation = 'softmax'))\n",
    "\n",
    "plot_model(cnn_model, show_shapes=True,to_file='cnn_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/300\n",
      "50000/50000 [==============================] - 10s 194us/sample - loss: 1.8325 - acc: 0.3359 - val_loss: 1.6303 - val_acc: 0.4168\n",
      "Epoch 2/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 1.5415 - acc: 0.4415 - val_loss: 1.4929 - val_acc: 0.4669\n",
      "Epoch 3/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 1.4281 - acc: 0.4879 - val_loss: 1.3916 - val_acc: 0.5084\n",
      "Epoch 4/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 1.3425 - acc: 0.5209 - val_loss: 1.3286 - val_acc: 0.5257\n",
      "Epoch 5/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 1.2711 - acc: 0.5499 - val_loss: 1.2892 - val_acc: 0.5387\n",
      "Epoch 6/300\n",
      "50000/50000 [==============================] - 8s 153us/sample - loss: 1.2141 - acc: 0.5704 - val_loss: 1.2582 - val_acc: 0.5613\n",
      "Epoch 7/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 1.1654 - acc: 0.5901 - val_loss: 1.2293 - val_acc: 0.5656\n",
      "Epoch 8/300\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 1.1246 - acc: 0.6065 - val_loss: 1.1873 - val_acc: 0.5904\n",
      "Epoch 9/300\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 1.0877 - acc: 0.6211 - val_loss: 1.1154 - val_acc: 0.6132\n",
      "Epoch 10/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 1.0554 - acc: 0.6323 - val_loss: 1.0786 - val_acc: 0.6262\n",
      "Epoch 11/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 1.0253 - acc: 0.6408 - val_loss: 1.1663 - val_acc: 0.5917\n",
      "Epoch 12/300\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.9975 - acc: 0.6510 - val_loss: 1.0957 - val_acc: 0.6195\n",
      "Epoch 13/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.9724 - acc: 0.6597 - val_loss: 1.0151 - val_acc: 0.6456\n",
      "Epoch 14/300\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 0.9488 - acc: 0.6701 - val_loss: 1.0312 - val_acc: 0.6425\n",
      "Epoch 15/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.9255 - acc: 0.6783 - val_loss: 1.0108 - val_acc: 0.6476\n",
      "Epoch 16/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.9032 - acc: 0.6854 - val_loss: 1.0545 - val_acc: 0.6366\n",
      "Epoch 17/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.8849 - acc: 0.6925 - val_loss: 1.0631 - val_acc: 0.6284\n",
      "Epoch 18/300\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.8645 - acc: 0.6998 - val_loss: 1.0291 - val_acc: 0.6432\n",
      "Epoch 19/300\n",
      "50000/50000 [==============================] - 8s 154us/sample - loss: 0.8442 - acc: 0.7052 - val_loss: 0.9908 - val_acc: 0.6556\n",
      "Epoch 20/300\n",
      "50000/50000 [==============================] - 8s 155us/sample - loss: 0.8262 - acc: 0.7143 - val_loss: 1.0126 - val_acc: 0.6524\n",
      "Epoch 21/300\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 0.8083 - acc: 0.7190 - val_loss: 0.9671 - val_acc: 0.6634\n",
      "Epoch 22/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.7918 - acc: 0.7242 - val_loss: 1.0066 - val_acc: 0.6513\n",
      "Epoch 23/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.7760 - acc: 0.7324 - val_loss: 0.9521 - val_acc: 0.6707\n",
      "Epoch 24/300\n",
      "50000/50000 [==============================] - 8s 153us/sample - loss: 0.7599 - acc: 0.7369 - val_loss: 0.9337 - val_acc: 0.6803\n",
      "Epoch 25/300\n",
      "50000/50000 [==============================] - 8s 154us/sample - loss: 0.7428 - acc: 0.7436 - val_loss: 0.9522 - val_acc: 0.6779\n",
      "Epoch 26/300\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 0.7276 - acc: 0.7500 - val_loss: 0.9660 - val_acc: 0.6721\n",
      "Epoch 27/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.7133 - acc: 0.7546 - val_loss: 0.9856 - val_acc: 0.6703\n",
      "Epoch 28/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.7001 - acc: 0.7582 - val_loss: 0.9498 - val_acc: 0.6756\n",
      "Epoch 29/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.6837 - acc: 0.7651 - val_loss: 0.9527 - val_acc: 0.6820\n",
      "Epoch 30/300\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 0.6702 - acc: 0.7692 - val_loss: 0.9848 - val_acc: 0.6701\n",
      "Epoch 31/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.6568 - acc: 0.7738 - val_loss: 0.9450 - val_acc: 0.6853\n",
      "Epoch 32/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.6432 - acc: 0.7780 - val_loss: 0.9704 - val_acc: 0.6784\n",
      "Epoch 33/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.6309 - acc: 0.7847 - val_loss: 0.9253 - val_acc: 0.6923\n",
      "Epoch 34/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.6168 - acc: 0.7898 - val_loss: 0.9835 - val_acc: 0.6800\n",
      "Epoch 35/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.6044 - acc: 0.7936 - val_loss: 0.9604 - val_acc: 0.6855\n",
      "Epoch 36/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.5929 - acc: 0.7988 - val_loss: 0.9556 - val_acc: 0.6884\n",
      "Epoch 37/300\n",
      "50000/50000 [==============================] - 8s 165us/sample - loss: 0.5796 - acc: 0.8027 - val_loss: 0.9487 - val_acc: 0.6915\n",
      "Epoch 38/300\n",
      "50000/50000 [==============================] - 8s 164us/sample - loss: 0.5690 - acc: 0.8053 - val_loss: 0.9569 - val_acc: 0.6934\n",
      "Epoch 39/300\n",
      "50000/50000 [==============================] - 8s 166us/sample - loss: 0.5569 - acc: 0.8097 - val_loss: 0.9900 - val_acc: 0.6830\n",
      "Epoch 40/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.5439 - acc: 0.8146 - val_loss: 0.9848 - val_acc: 0.6867\n",
      "Epoch 41/300\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 0.5319 - acc: 0.8185 - val_loss: 0.9815 - val_acc: 0.6899\n",
      "Epoch 42/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.5210 - acc: 0.8241 - val_loss: 0.9628 - val_acc: 0.6962\n",
      "Epoch 43/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.5113 - acc: 0.8252 - val_loss: 0.9996 - val_acc: 0.6889\n",
      "Epoch 44/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.4995 - acc: 0.8317 - val_loss: 0.9720 - val_acc: 0.6965\n",
      "Epoch 45/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.4870 - acc: 0.8365 - val_loss: 1.0249 - val_acc: 0.6872\n",
      "Epoch 46/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.4771 - acc: 0.8382 - val_loss: 1.0242 - val_acc: 0.6935\n",
      "Epoch 47/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.4659 - acc: 0.8410 - val_loss: 1.0589 - val_acc: 0.6771\n",
      "Epoch 48/300\n",
      "50000/50000 [==============================] - 8s 155us/sample - loss: 0.4566 - acc: 0.8456 - val_loss: 0.9916 - val_acc: 0.7009\n",
      "Epoch 49/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.4461 - acc: 0.8495 - val_loss: 1.0699 - val_acc: 0.6789\n",
      "Epoch 50/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.4357 - acc: 0.8530 - val_loss: 1.0523 - val_acc: 0.6953\n",
      "Epoch 51/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.4251 - acc: 0.8563 - val_loss: 1.0920 - val_acc: 0.6832\n",
      "Epoch 52/300\n",
      "50000/50000 [==============================] - 8s 164us/sample - loss: 0.4146 - acc: 0.8595 - val_loss: 1.0798 - val_acc: 0.6889\n",
      "Epoch 53/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.4057 - acc: 0.8626 - val_loss: 1.0691 - val_acc: 0.6904\n",
      "Epoch 54/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.3963 - acc: 0.8663 - val_loss: 1.0965 - val_acc: 0.6931\n",
      "Epoch 55/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.3871 - acc: 0.8701 - val_loss: 1.0817 - val_acc: 0.6926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.3768 - acc: 0.8745 - val_loss: 1.1216 - val_acc: 0.6923\n",
      "Epoch 57/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.3675 - acc: 0.8761 - val_loss: 1.1409 - val_acc: 0.6933\n",
      "Epoch 58/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.3570 - acc: 0.8807 - val_loss: 1.1302 - val_acc: 0.6907\n",
      "Epoch 59/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.3489 - acc: 0.8834 - val_loss: 1.1902 - val_acc: 0.6795\n",
      "Epoch 60/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.3384 - acc: 0.8866 - val_loss: 1.2036 - val_acc: 0.6848\n",
      "Epoch 61/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.3316 - acc: 0.8896 - val_loss: 1.1610 - val_acc: 0.6953\n",
      "Epoch 62/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.3209 - acc: 0.8934 - val_loss: 1.2652 - val_acc: 0.6764\n",
      "Epoch 63/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.3127 - acc: 0.8960 - val_loss: 1.2078 - val_acc: 0.6873\n",
      "Epoch 64/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.3041 - acc: 0.8991 - val_loss: 1.2409 - val_acc: 0.6771\n",
      "Epoch 65/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.2956 - acc: 0.9021 - val_loss: 1.2418 - val_acc: 0.6852\n",
      "Epoch 66/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.2855 - acc: 0.9048 - val_loss: 1.2753 - val_acc: 0.6834\n",
      "Epoch 67/300\n",
      "50000/50000 [==============================] - 8s 153us/sample - loss: 0.2787 - acc: 0.9079 - val_loss: 1.2770 - val_acc: 0.6874\n",
      "Epoch 68/300\n",
      "50000/50000 [==============================] - 8s 155us/sample - loss: 0.2695 - acc: 0.9116 - val_loss: 1.2951 - val_acc: 0.6895\n",
      "Epoch 69/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.2626 - acc: 0.9136 - val_loss: 1.3023 - val_acc: 0.6915\n",
      "Epoch 70/300\n",
      "50000/50000 [==============================] - 8s 152us/sample - loss: 0.2551 - acc: 0.9169 - val_loss: 1.3456 - val_acc: 0.6806\n",
      "Epoch 71/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.2467 - acc: 0.9187 - val_loss: 1.3540 - val_acc: 0.6832\n",
      "Epoch 72/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.2384 - acc: 0.9224 - val_loss: 1.3795 - val_acc: 0.6785\n",
      "Epoch 73/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.2301 - acc: 0.9254 - val_loss: 1.4269 - val_acc: 0.6760\n",
      "Epoch 74/300\n",
      "50000/50000 [==============================] - 8s 155us/sample - loss: 0.2230 - acc: 0.9276 - val_loss: 1.4015 - val_acc: 0.6890\n",
      "Epoch 75/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.2149 - acc: 0.9305 - val_loss: 1.4399 - val_acc: 0.6744\n",
      "Epoch 76/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.2077 - acc: 0.9334 - val_loss: 1.4741 - val_acc: 0.6814\n",
      "Epoch 77/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.2019 - acc: 0.9350 - val_loss: 1.4835 - val_acc: 0.6860\n",
      "Epoch 78/300\n",
      "50000/50000 [==============================] - 8s 155us/sample - loss: 0.1950 - acc: 0.9373 - val_loss: 1.5242 - val_acc: 0.6774\n",
      "Epoch 79/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.1863 - acc: 0.9404 - val_loss: 1.6012 - val_acc: 0.6751\n",
      "Epoch 80/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.1811 - acc: 0.9421 - val_loss: 1.5845 - val_acc: 0.6789\n",
      "Epoch 81/300\n",
      "50000/50000 [==============================] - 8s 164us/sample - loss: 0.1739 - acc: 0.9454 - val_loss: 1.5802 - val_acc: 0.6855\n",
      "Epoch 82/300\n",
      "50000/50000 [==============================] - 8s 170us/sample - loss: 0.1678 - acc: 0.9485 - val_loss: 1.5820 - val_acc: 0.6786\n",
      "Epoch 83/300\n",
      "50000/50000 [==============================] - 8s 165us/sample - loss: 0.1619 - acc: 0.9492 - val_loss: 1.6131 - val_acc: 0.6802\n",
      "Epoch 84/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.1564 - acc: 0.9508 - val_loss: 1.6637 - val_acc: 0.6773\n",
      "Epoch 85/300\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 0.1495 - acc: 0.9527 - val_loss: 1.6807 - val_acc: 0.6769\n",
      "Epoch 86/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.1427 - acc: 0.9559 - val_loss: 1.7241 - val_acc: 0.6789\n",
      "Epoch 87/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.1373 - acc: 0.9575 - val_loss: 1.7216 - val_acc: 0.6795\n",
      "Epoch 88/300\n",
      "50000/50000 [==============================] - 8s 165us/sample - loss: 0.1316 - acc: 0.9597 - val_loss: 1.7947 - val_acc: 0.6754\n",
      "Epoch 89/300\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 0.1270 - acc: 0.9605 - val_loss: 1.7846 - val_acc: 0.6777\n",
      "Epoch 90/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.1218 - acc: 0.9622 - val_loss: 1.8176 - val_acc: 0.6784\n",
      "Epoch 91/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.1158 - acc: 0.9649 - val_loss: 1.8560 - val_acc: 0.6780\n",
      "Epoch 92/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.1121 - acc: 0.9660 - val_loss: 1.9210 - val_acc: 0.6713\n",
      "Epoch 93/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.1072 - acc: 0.9681 - val_loss: 1.8850 - val_acc: 0.6738\n",
      "Epoch 94/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.1031 - acc: 0.9688 - val_loss: 1.9592 - val_acc: 0.6742\n",
      "Epoch 95/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0974 - acc: 0.9715 - val_loss: 1.9829 - val_acc: 0.6762\n",
      "Epoch 96/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0937 - acc: 0.9728 - val_loss: 1.9792 - val_acc: 0.6722\n",
      "Epoch 97/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0903 - acc: 0.9734 - val_loss: 2.0777 - val_acc: 0.6672\n",
      "Epoch 98/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.0854 - acc: 0.9747 - val_loss: 2.0614 - val_acc: 0.6717\n",
      "Epoch 99/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.0820 - acc: 0.9760 - val_loss: 2.1731 - val_acc: 0.6628\n",
      "Epoch 100/300\n",
      "50000/50000 [==============================] - 8s 155us/sample - loss: 0.0781 - acc: 0.9771 - val_loss: 2.1882 - val_acc: 0.6643\n",
      "Epoch 101/300\n",
      "50000/50000 [==============================] - 8s 154us/sample - loss: 0.0755 - acc: 0.9780 - val_loss: 2.1148 - val_acc: 0.6749\n",
      "Epoch 102/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.0722 - acc: 0.9793 - val_loss: 2.1413 - val_acc: 0.6743\n",
      "Epoch 103/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0678 - acc: 0.9807 - val_loss: 2.2632 - val_acc: 0.6631\n",
      "Epoch 104/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0643 - acc: 0.9814 - val_loss: 2.2219 - val_acc: 0.6693\n",
      "Epoch 105/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0605 - acc: 0.9831 - val_loss: 2.2760 - val_acc: 0.6702\n",
      "Epoch 106/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0585 - acc: 0.9834 - val_loss: 2.2554 - val_acc: 0.6739\n",
      "Epoch 107/300\n",
      "50000/50000 [==============================] - 8s 155us/sample - loss: 0.0566 - acc: 0.9840 - val_loss: 2.3274 - val_acc: 0.6684\n",
      "Epoch 108/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0544 - acc: 0.9851 - val_loss: 2.3381 - val_acc: 0.6695\n",
      "Epoch 109/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.0507 - acc: 0.9857 - val_loss: 2.3379 - val_acc: 0.6724\n",
      "Epoch 110/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0490 - acc: 0.9865 - val_loss: 2.3673 - val_acc: 0.6705\n",
      "Epoch 111/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0475 - acc: 0.9866 - val_loss: 2.3836 - val_acc: 0.6708\n",
      "Epoch 112/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0449 - acc: 0.9873 - val_loss: 2.4271 - val_acc: 0.6717\n",
      "Epoch 113/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0427 - acc: 0.9887 - val_loss: 2.4938 - val_acc: 0.6641\n",
      "Epoch 114/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0411 - acc: 0.9888 - val_loss: 2.4348 - val_acc: 0.6717\n",
      "Epoch 115/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.0395 - acc: 0.9892 - val_loss: 2.4961 - val_acc: 0.6741\n",
      "Epoch 116/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0379 - acc: 0.9893 - val_loss: 2.5607 - val_acc: 0.6687\n",
      "Epoch 117/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0354 - acc: 0.9906 - val_loss: 2.5309 - val_acc: 0.6670\n",
      "Epoch 118/300\n",
      "50000/50000 [==============================] - 8s 155us/sample - loss: 0.0357 - acc: 0.9903 - val_loss: 2.5871 - val_acc: 0.6714\n",
      "Epoch 119/300\n",
      "50000/50000 [==============================] - 8s 154us/sample - loss: 0.0321 - acc: 0.9922 - val_loss: 2.7229 - val_acc: 0.6532\n",
      "Epoch 120/300\n",
      "50000/50000 [==============================] - 8s 155us/sample - loss: 0.0317 - acc: 0.9921 - val_loss: 2.6600 - val_acc: 0.6687\n",
      "Epoch 121/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0299 - acc: 0.9921 - val_loss: 2.7468 - val_acc: 0.6620\n",
      "Epoch 122/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0285 - acc: 0.9927 - val_loss: 2.6734 - val_acc: 0.6677\n",
      "Epoch 123/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0283 - acc: 0.9927 - val_loss: 2.6745 - val_acc: 0.6706\n",
      "Epoch 124/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.0272 - acc: 0.9922 - val_loss: 2.7326 - val_acc: 0.6704\n",
      "Epoch 125/300\n",
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.0254 - acc: 0.9932 - val_loss: 2.7999 - val_acc: 0.6650\n",
      "Epoch 126/300\n",
      "50000/50000 [==============================] - 8s 165us/sample - loss: 0.0254 - acc: 0.9933 - val_loss: 2.7223 - val_acc: 0.6713\n",
      "Epoch 127/300\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 0.0239 - acc: 0.9936 - val_loss: 2.7817 - val_acc: 0.6721\n",
      "Epoch 128/300\n",
      "50000/50000 [==============================] - 8s 164us/sample - loss: 0.0237 - acc: 0.9937 - val_loss: 2.7888 - val_acc: 0.6705\n",
      "Epoch 129/300\n",
      "50000/50000 [==============================] - 8s 164us/sample - loss: 0.0232 - acc: 0.9934 - val_loss: 2.8169 - val_acc: 0.6668\n",
      "Epoch 130/300\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 0.0225 - acc: 0.9937 - val_loss: 2.8885 - val_acc: 0.6641\n",
      "Epoch 131/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.0216 - acc: 0.9939 - val_loss: 2.8718 - val_acc: 0.6664\n",
      "Epoch 132/300\n",
      "50000/50000 [==============================] - 8s 164us/sample - loss: 0.0207 - acc: 0.9946 - val_loss: 2.9519 - val_acc: 0.6610\n",
      "Epoch 133/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0197 - acc: 0.9948 - val_loss: 2.9094 - val_acc: 0.6661\n",
      "Epoch 134/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0192 - acc: 0.9947 - val_loss: 2.9456 - val_acc: 0.6619\n",
      "Epoch 135/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0191 - acc: 0.9951 - val_loss: 2.9235 - val_acc: 0.6667\n",
      "Epoch 136/300\n",
      "50000/50000 [==============================] - 8s 152us/sample - loss: 0.0188 - acc: 0.9950 - val_loss: 2.9402 - val_acc: 0.6661\n",
      "Epoch 137/300\n",
      "50000/50000 [==============================] - 8s 152us/sample - loss: 0.0181 - acc: 0.9948 - val_loss: 3.0366 - val_acc: 0.6621\n",
      "Epoch 138/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.0173 - acc: 0.9954 - val_loss: 2.9971 - val_acc: 0.6613\n",
      "Epoch 139/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0171 - acc: 0.9949 - val_loss: 3.0045 - val_acc: 0.6673\n",
      "Epoch 140/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0168 - acc: 0.9955 - val_loss: 2.9818 - val_acc: 0.6691\n",
      "Epoch 141/300\n",
      "50000/50000 [==============================] - 8s 152us/sample - loss: 0.0158 - acc: 0.9957 - val_loss: 3.0485 - val_acc: 0.6605\n",
      "Epoch 142/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0162 - acc: 0.9955 - val_loss: 3.0557 - val_acc: 0.6681\n",
      "Epoch 143/300\n",
      "50000/50000 [==============================] - 8s 155us/sample - loss: 0.0160 - acc: 0.9953 - val_loss: 3.0348 - val_acc: 0.6680\n",
      "Epoch 144/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0155 - acc: 0.9954 - val_loss: 3.0662 - val_acc: 0.6699\n",
      "Epoch 145/300\n",
      "50000/50000 [==============================] - 8s 153us/sample - loss: 0.0147 - acc: 0.9961 - val_loss: 3.1050 - val_acc: 0.6657\n",
      "Epoch 146/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0140 - acc: 0.9963 - val_loss: 3.1260 - val_acc: 0.6653\n",
      "Epoch 147/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0143 - acc: 0.9965 - val_loss: 3.0749 - val_acc: 0.6693\n",
      "Epoch 148/300\n",
      "50000/50000 [==============================] - 8s 155us/sample - loss: 0.0150 - acc: 0.9955 - val_loss: 3.0855 - val_acc: 0.6651\n",
      "Epoch 149/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0145 - acc: 0.9958 - val_loss: 3.1590 - val_acc: 0.6641\n",
      "Epoch 150/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0141 - acc: 0.9959 - val_loss: 3.1172 - val_acc: 0.6665\n",
      "Epoch 151/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0142 - acc: 0.9960 - val_loss: 3.1474 - val_acc: 0.6673\n",
      "Epoch 152/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0135 - acc: 0.9962 - val_loss: 3.2222 - val_acc: 0.6633\n",
      "Epoch 153/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0135 - acc: 0.9963 - val_loss: 3.1512 - val_acc: 0.6679\n",
      "Epoch 154/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0128 - acc: 0.9963 - val_loss: 3.1709 - val_acc: 0.6681\n",
      "Epoch 155/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.0129 - acc: 0.9963 - val_loss: 3.1970 - val_acc: 0.6688\n",
      "Epoch 156/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0121 - acc: 0.9966 - val_loss: 3.3240 - val_acc: 0.6597\n",
      "Epoch 157/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0117 - acc: 0.9966 - val_loss: 3.1990 - val_acc: 0.6666\n",
      "Epoch 158/300\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 0.0113 - acc: 0.9969 - val_loss: 3.2170 - val_acc: 0.6684\n",
      "Epoch 159/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0113 - acc: 0.9968 - val_loss: 3.2220 - val_acc: 0.6709\n",
      "Epoch 160/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.0112 - acc: 0.9967 - val_loss: 3.3135 - val_acc: 0.6582\n",
      "Epoch 161/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.0111 - acc: 0.9965 - val_loss: 3.2641 - val_acc: 0.6709\n",
      "Epoch 162/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0112 - acc: 0.9968 - val_loss: 3.2667 - val_acc: 0.6693\n",
      "Epoch 163/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0105 - acc: 0.9970 - val_loss: 3.2549 - val_acc: 0.6681\n",
      "Epoch 164/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.0106 - acc: 0.9971 - val_loss: 3.3521 - val_acc: 0.6643\n",
      "Epoch 165/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0111 - acc: 0.9968 - val_loss: 3.3235 - val_acc: 0.6695\n",
      "Epoch 166/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0103 - acc: 0.9971 - val_loss: 3.3319 - val_acc: 0.6657\n",
      "Epoch 167/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.0101 - acc: 0.9970 - val_loss: 3.3372 - val_acc: 0.6689\n",
      "Epoch 168/300\n",
      "50000/50000 [==============================] - 8s 155us/sample - loss: 0.0104 - acc: 0.9969 - val_loss: 3.3938 - val_acc: 0.6629\n",
      "Epoch 169/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0098 - acc: 0.9971 - val_loss: 3.3766 - val_acc: 0.6694\n",
      "Epoch 170/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0091 - acc: 0.9974 - val_loss: 3.3857 - val_acc: 0.6636\n",
      "Epoch 171/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0099 - acc: 0.9974 - val_loss: 3.3260 - val_acc: 0.6698\n",
      "Epoch 172/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.0096 - acc: 0.9974 - val_loss: 3.3601 - val_acc: 0.6694\n",
      "Epoch 173/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0099 - acc: 0.9971 - val_loss: 3.3916 - val_acc: 0.6665\n",
      "Epoch 174/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0093 - acc: 0.9972 - val_loss: 3.4378 - val_acc: 0.6644\n",
      "Epoch 175/300\n",
      "50000/50000 [==============================] - 8s 154us/sample - loss: 0.0090 - acc: 0.9973 - val_loss: 3.4052 - val_acc: 0.6650\n",
      "Epoch 176/300\n",
      "50000/50000 [==============================] - 8s 152us/sample - loss: 0.0098 - acc: 0.9968 - val_loss: 3.4155 - val_acc: 0.6657\n",
      "Epoch 177/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0098 - acc: 0.9971 - val_loss: 3.4455 - val_acc: 0.6641\n",
      "Epoch 178/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0086 - acc: 0.9974 - val_loss: 3.4367 - val_acc: 0.6672\n",
      "Epoch 179/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0096 - acc: 0.9970 - val_loss: 3.4407 - val_acc: 0.6671\n",
      "Epoch 180/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.0090 - acc: 0.9974 - val_loss: 3.4540 - val_acc: 0.6672\n",
      "Epoch 181/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.0083 - acc: 0.9976 - val_loss: 3.4328 - val_acc: 0.6668\n",
      "Epoch 182/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0084 - acc: 0.9976 - val_loss: 3.4972 - val_acc: 0.6656\n",
      "Epoch 183/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0074 - acc: 0.9979 - val_loss: 3.5518 - val_acc: 0.6618\n",
      "Epoch 184/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0092 - acc: 0.9973 - val_loss: 3.4552 - val_acc: 0.6676\n",
      "Epoch 185/300\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 0.0084 - acc: 0.9975 - val_loss: 3.5077 - val_acc: 0.6656\n",
      "Epoch 186/300\n",
      "50000/50000 [==============================] - 8s 164us/sample - loss: 0.0084 - acc: 0.9974 - val_loss: 3.4735 - val_acc: 0.6682\n",
      "Epoch 187/300\n",
      "50000/50000 [==============================] - 8s 164us/sample - loss: 0.0086 - acc: 0.9974 - val_loss: 3.5282 - val_acc: 0.6639\n",
      "Epoch 188/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0083 - acc: 0.9974 - val_loss: 3.5925 - val_acc: 0.6610\n",
      "Epoch 189/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.0081 - acc: 0.9975 - val_loss: 3.5187 - val_acc: 0.6672\n",
      "Epoch 190/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.0074 - acc: 0.9979 - val_loss: 3.5033 - val_acc: 0.6670\n",
      "Epoch 191/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.0079 - acc: 0.9976 - val_loss: 3.5406 - val_acc: 0.6657\n",
      "Epoch 192/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.0077 - acc: 0.9976 - val_loss: 3.5066 - val_acc: 0.6689\n",
      "Epoch 193/300\n",
      "50000/50000 [==============================] - 8s 153us/sample - loss: 0.0078 - acc: 0.9977 - val_loss: 3.5665 - val_acc: 0.6622\n",
      "Epoch 194/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.0071 - acc: 0.9978 - val_loss: 3.5462 - val_acc: 0.6652\n",
      "Epoch 195/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0079 - acc: 0.9974 - val_loss: 3.6046 - val_acc: 0.6634\n",
      "Epoch 196/300\n",
      "50000/50000 [==============================] - 8s 154us/sample - loss: 0.0082 - acc: 0.9976 - val_loss: 3.5590 - val_acc: 0.6671\n",
      "Epoch 197/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.0071 - acc: 0.9976 - val_loss: 3.7194 - val_acc: 0.6570\n",
      "Epoch 198/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0069 - acc: 0.9979 - val_loss: 3.5792 - val_acc: 0.6662\n",
      "Epoch 199/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0077 - acc: 0.9977 - val_loss: 3.6220 - val_acc: 0.6606\n",
      "Epoch 200/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0067 - acc: 0.9979 - val_loss: 3.6546 - val_acc: 0.6642\n",
      "Epoch 201/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0071 - acc: 0.9980 - val_loss: 3.5911 - val_acc: 0.6640\n",
      "Epoch 202/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0076 - acc: 0.9977 - val_loss: 3.6338 - val_acc: 0.6620\n",
      "Epoch 203/300\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 0.0072 - acc: 0.9978 - val_loss: 3.5931 - val_acc: 0.6641\n",
      "Epoch 204/300\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 0.0067 - acc: 0.9980 - val_loss: 3.6355 - val_acc: 0.6656\n",
      "Epoch 205/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.0070 - acc: 0.9980 - val_loss: 3.6251 - val_acc: 0.6650\n",
      "Epoch 206/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.0068 - acc: 0.9980 - val_loss: 3.6889 - val_acc: 0.6640\n",
      "Epoch 207/300\n",
      "50000/50000 [==============================] - 8s 153us/sample - loss: 0.0076 - acc: 0.9977 - val_loss: 3.6672 - val_acc: 0.6632\n",
      "Epoch 208/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.0070 - acc: 0.9980 - val_loss: 3.7342 - val_acc: 0.6599\n",
      "Epoch 209/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0072 - acc: 0.9978 - val_loss: 3.6670 - val_acc: 0.6654\n",
      "Epoch 210/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0069 - acc: 0.9978 - val_loss: 3.6521 - val_acc: 0.6685\n",
      "Epoch 211/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0061 - acc: 0.9984 - val_loss: 3.6620 - val_acc: 0.6681\n",
      "Epoch 212/300\n",
      "50000/50000 [==============================] - 8s 153us/sample - loss: 0.0071 - acc: 0.9980 - val_loss: 3.6968 - val_acc: 0.6648\n",
      "Epoch 213/300\n",
      "50000/50000 [==============================] - 8s 154us/sample - loss: 0.0065 - acc: 0.9982 - val_loss: 3.7035 - val_acc: 0.6641\n",
      "Epoch 214/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0071 - acc: 0.9978 - val_loss: 3.6603 - val_acc: 0.6672\n",
      "Epoch 215/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0064 - acc: 0.9981 - val_loss: 3.6922 - val_acc: 0.6650\n",
      "Epoch 216/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.0064 - acc: 0.9979 - val_loss: 3.6535 - val_acc: 0.6665\n",
      "Epoch 217/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0070 - acc: 0.9979 - val_loss: 3.6577 - val_acc: 0.6630\n",
      "Epoch 218/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0050 - acc: 0.9985 - val_loss: 3.6791 - val_acc: 0.6659\n",
      "Epoch 219/300\n",
      "50000/50000 [==============================] - 8s 153us/sample - loss: 0.0064 - acc: 0.9980 - val_loss: 3.7033 - val_acc: 0.6671\n",
      "Epoch 220/300\n",
      "50000/50000 [==============================] - 8s 154us/sample - loss: 0.0059 - acc: 0.9983 - val_loss: 3.7529 - val_acc: 0.6616\n",
      "Epoch 221/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.0061 - acc: 0.9982 - val_loss: 3.7081 - val_acc: 0.6648\n",
      "Epoch 222/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0067 - acc: 0.9978 - val_loss: 3.7110 - val_acc: 0.6636\n",
      "Epoch 223/300\n",
      "50000/50000 [==============================] - 8s 161us/sample - loss: 0.0061 - acc: 0.9981 - val_loss: 3.7942 - val_acc: 0.6567\n",
      "Epoch 224/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0059 - acc: 0.9982 - val_loss: 3.7428 - val_acc: 0.6647\n",
      "Epoch 225/300\n",
      "50000/50000 [==============================] - 8s 154us/sample - loss: 0.0055 - acc: 0.9982 - val_loss: 3.7301 - val_acc: 0.6651\n",
      "Epoch 226/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0059 - acc: 0.9982 - val_loss: 3.7335 - val_acc: 0.6648\n",
      "Epoch 227/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0060 - acc: 0.9983 - val_loss: 3.7516 - val_acc: 0.6616\n",
      "Epoch 228/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0061 - acc: 0.9980 - val_loss: 3.7432 - val_acc: 0.6644\n",
      "Epoch 229/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0060 - acc: 0.9982 - val_loss: 3.7736 - val_acc: 0.6653\n",
      "Epoch 230/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0059 - acc: 0.9983 - val_loss: 3.7537 - val_acc: 0.6654\n",
      "Epoch 231/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0058 - acc: 0.9983 - val_loss: 3.7434 - val_acc: 0.6672\n",
      "Epoch 232/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0071 - acc: 0.9980 - val_loss: 3.7841 - val_acc: 0.6625\n",
      "Epoch 233/300\n",
      "50000/50000 [==============================] - 8s 152us/sample - loss: 0.0053 - acc: 0.9983 - val_loss: 3.7492 - val_acc: 0.6683\n",
      "Epoch 234/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0062 - acc: 0.9981 - val_loss: 3.7644 - val_acc: 0.6658\n",
      "Epoch 235/300\n",
      "50000/50000 [==============================] - 8s 154us/sample - loss: 0.0056 - acc: 0.9985 - val_loss: 3.7639 - val_acc: 0.6650\n",
      "Epoch 236/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0056 - acc: 0.9981 - val_loss: 3.7476 - val_acc: 0.6688\n",
      "Epoch 237/300\n",
      "50000/50000 [==============================] - 8s 155us/sample - loss: 0.0068 - acc: 0.9981 - val_loss: 3.7700 - val_acc: 0.6670\n",
      "Epoch 238/300\n",
      "50000/50000 [==============================] - 8s 151us/sample - loss: 0.0059 - acc: 0.9982 - val_loss: 3.8079 - val_acc: 0.6636\n",
      "Epoch 239/300\n",
      "50000/50000 [==============================] - 8s 154us/sample - loss: 0.0053 - acc: 0.9986 - val_loss: 3.7734 - val_acc: 0.6661\n",
      "Epoch 240/300\n",
      "50000/50000 [==============================] - 8s 154us/sample - loss: 0.0052 - acc: 0.9983 - val_loss: 3.8034 - val_acc: 0.6668\n",
      "Epoch 241/300\n",
      "50000/50000 [==============================] - 8s 155us/sample - loss: 0.0057 - acc: 0.9984 - val_loss: 3.8065 - val_acc: 0.6644\n",
      "Epoch 242/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0055 - acc: 0.9982 - val_loss: 3.7926 - val_acc: 0.6647\n",
      "Epoch 243/300\n",
      "50000/50000 [==============================] - 8s 153us/sample - loss: 0.0055 - acc: 0.9984 - val_loss: 3.8809 - val_acc: 0.6605\n",
      "Epoch 244/300\n",
      "50000/50000 [==============================] - 8s 155us/sample - loss: 0.0052 - acc: 0.9985 - val_loss: 3.8239 - val_acc: 0.6637\n",
      "Epoch 245/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0054 - acc: 0.9983 - val_loss: 3.8612 - val_acc: 0.6630\n",
      "Epoch 246/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.0054 - acc: 0.9984 - val_loss: 3.8164 - val_acc: 0.6671\n",
      "Epoch 247/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0057 - acc: 0.9982 - val_loss: 3.7966 - val_acc: 0.6683\n",
      "Epoch 248/300\n",
      "50000/50000 [==============================] - 8s 155us/sample - loss: 0.0053 - acc: 0.9984 - val_loss: 3.8332 - val_acc: 0.6634\n",
      "Epoch 249/300\n",
      "50000/50000 [==============================] - 8s 154us/sample - loss: 0.0058 - acc: 0.9981 - val_loss: 3.8191 - val_acc: 0.6645\n",
      "Epoch 250/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0053 - acc: 0.9987 - val_loss: 3.9882 - val_acc: 0.6544\n",
      "Epoch 251/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0067 - acc: 0.9979 - val_loss: 3.8572 - val_acc: 0.6618\n",
      "Epoch 252/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.0058 - acc: 0.9983 - val_loss: 3.8467 - val_acc: 0.6654\n",
      "Epoch 253/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0051 - acc: 0.9983 - val_loss: 3.8399 - val_acc: 0.6643\n",
      "Epoch 254/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.0043 - acc: 0.9986 - val_loss: 3.8293 - val_acc: 0.6646\n",
      "Epoch 255/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0059 - acc: 0.9983 - val_loss: 3.8628 - val_acc: 0.6658\n",
      "Epoch 256/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.0051 - acc: 0.9984 - val_loss: 3.8662 - val_acc: 0.6634\n",
      "Epoch 257/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0047 - acc: 0.9986 - val_loss: 3.8207 - val_acc: 0.6673\n",
      "Epoch 258/300\n",
      "50000/50000 [==============================] - 8s 151us/sample - loss: 0.0049 - acc: 0.9985 - val_loss: 3.8475 - val_acc: 0.6641\n",
      "Epoch 259/300\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 0.0044 - acc: 0.9986 - val_loss: 3.8273 - val_acc: 0.6671\n",
      "Epoch 260/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0054 - acc: 0.9985 - val_loss: 3.9698 - val_acc: 0.6565\n",
      "Epoch 261/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0054 - acc: 0.9984 - val_loss: 3.8580 - val_acc: 0.6649\n",
      "Epoch 262/300\n",
      "50000/50000 [==============================] - 8s 155us/sample - loss: 0.0056 - acc: 0.9985 - val_loss: 3.8645 - val_acc: 0.6649\n",
      "Epoch 263/300\n",
      "50000/50000 [==============================] - 8s 158us/sample - loss: 0.0049 - acc: 0.9988 - val_loss: 3.8685 - val_acc: 0.6671\n",
      "Epoch 264/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0055 - acc: 0.9984 - val_loss: 3.8588 - val_acc: 0.6673\n",
      "Epoch 265/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0046 - acc: 0.9985 - val_loss: 3.8647 - val_acc: 0.6665\n",
      "Epoch 266/300\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 0.0054 - acc: 0.9985 - val_loss: 3.9168 - val_acc: 0.6626\n",
      "Epoch 267/300\n",
      "50000/50000 [==============================] - 8s 165us/sample - loss: 0.0046 - acc: 0.9986 - val_loss: 3.9015 - val_acc: 0.6635\n",
      "Epoch 268/300\n",
      "50000/50000 [==============================] - 8s 165us/sample - loss: 0.0044 - acc: 0.9987 - val_loss: 3.8913 - val_acc: 0.6650\n",
      "Epoch 269/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0045 - acc: 0.9986 - val_loss: 3.8788 - val_acc: 0.6646\n",
      "Epoch 270/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0045 - acc: 0.9987 - val_loss: 3.9543 - val_acc: 0.6620\n",
      "Epoch 271/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0054 - acc: 0.9985 - val_loss: 3.9537 - val_acc: 0.6625\n",
      "Epoch 272/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0045 - acc: 0.9986 - val_loss: 3.9187 - val_acc: 0.6639\n",
      "Epoch 273/300\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0047 - acc: 0.9984 - val_loss: 3.9025 - val_acc: 0.6660\n",
      "Epoch 274/300\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 0.0043 - acc: 0.9985 - val_loss: 3.8770 - val_acc: 0.6672\n",
      "Epoch 275/300\n",
      "50000/50000 [==============================] - 8s 160us/sample - loss: 0.0052 - acc: 0.9986 - val_loss: 3.8912 - val_acc: 0.6651\n",
      "Epoch 276/300\n",
      "50000/50000 [==============================] - 8s 162us/sample - loss: 0.0042 - acc: 0.9987 - val_loss: 3.9150 - val_acc: 0.6663\n",
      "Epoch 277/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0042 - acc: 0.9988 - val_loss: 3.9264 - val_acc: 0.6654\n",
      "Epoch 278/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0037 - acc: 0.9987 - val_loss: 3.9049 - val_acc: 0.6671\n",
      "Epoch 279/300\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 0.0041 - acc: 0.9988 - val_loss: 3.9208 - val_acc: 0.6666\n",
      "Epoch 280/300\n",
      "50000/50000 [==============================] - 8s 152us/sample - loss: 0.0052 - acc: 0.9988 - val_loss: 3.9022 - val_acc: 0.6656\n",
      "Epoch 281/300\n",
      "50000/50000 [==============================] - 8s 154us/sample - loss: 0.0042 - acc: 0.9986 - val_loss: 3.9484 - val_acc: 0.6634\n",
      "Epoch 282/300\n",
      "50000/50000 [==============================] - 8s 155us/sample - loss: 0.0038 - acc: 0.9989 - val_loss: 3.9353 - val_acc: 0.6672\n",
      "Epoch 283/300\n",
      "50000/50000 [==============================] - 8s 169us/sample - loss: 0.0051 - acc: 0.9987 - val_loss: 3.9504 - val_acc: 0.6654\n",
      "Epoch 284/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 30s 591us/sample - loss: 0.0047 - acc: 0.9986 - val_loss: 3.9828 - val_acc: 0.6618\n",
      "Epoch 285/300\n",
      "50000/50000 [==============================] - 34s 670us/sample - loss: 0.0048 - acc: 0.9986 - val_loss: 3.9585 - val_acc: 0.6632\n",
      "Epoch 286/300\n",
      "50000/50000 [==============================] - 34s 675us/sample - loss: 0.0046 - acc: 0.9986 - val_loss: 3.9631 - val_acc: 0.6662\n",
      "Epoch 287/300\n",
      "50000/50000 [==============================] - 33s 669us/sample - loss: 0.0048 - acc: 0.9987 - val_loss: 3.9486 - val_acc: 0.6688\n",
      "Epoch 288/300\n",
      "50000/50000 [==============================] - 34s 670us/sample - loss: 0.0040 - acc: 0.9988 - val_loss: 3.9834 - val_acc: 0.6623\n",
      "Epoch 289/300\n",
      "50000/50000 [==============================] - 33s 667us/sample - loss: 0.0036 - acc: 0.9989 - val_loss: 3.9266 - val_acc: 0.6662\n",
      "Epoch 290/300\n",
      "50000/50000 [==============================] - 33s 669us/sample - loss: 0.0040 - acc: 0.9988 - val_loss: 3.9431 - val_acc: 0.6693\n",
      "Epoch 291/300\n",
      "50000/50000 [==============================] - 34s 670us/sample - loss: 0.0042 - acc: 0.9986 - val_loss: 3.9628 - val_acc: 0.6643\n",
      "Epoch 292/300\n",
      "50000/50000 [==============================] - 33s 670us/sample - loss: 0.0041 - acc: 0.9988 - val_loss: 3.9581 - val_acc: 0.6654\n",
      "Epoch 293/300\n",
      "50000/50000 [==============================] - 34s 672us/sample - loss: 0.0044 - acc: 0.9986 - val_loss: 3.9422 - val_acc: 0.6657\n",
      "Epoch 294/300\n",
      "50000/50000 [==============================] - 33s 670us/sample - loss: 0.0047 - acc: 0.9987 - val_loss: 3.9775 - val_acc: 0.6649\n",
      "Epoch 295/300\n",
      "50000/50000 [==============================] - 33s 669us/sample - loss: 0.0036 - acc: 0.9988 - val_loss: 3.9572 - val_acc: 0.6648\n",
      "Epoch 296/300\n",
      "50000/50000 [==============================] - 34s 673us/sample - loss: 0.0036 - acc: 0.9990 - val_loss: 3.9426 - val_acc: 0.6658\n",
      "Epoch 297/300\n",
      "50000/50000 [==============================] - 34s 680us/sample - loss: 0.0047 - acc: 0.9987 - val_loss: 3.9949 - val_acc: 0.6663\n",
      "Epoch 298/300\n",
      "50000/50000 [==============================] - 34s 671us/sample - loss: 0.0044 - acc: 0.9987 - val_loss: 3.9550 - val_acc: 0.6661\n",
      "Epoch 299/300\n",
      "50000/50000 [==============================] - 34s 679us/sample - loss: 0.0038 - acc: 0.9988 - val_loss: 4.0243 - val_acc: 0.6628\n",
      "Epoch 300/300\n",
      "50000/50000 [==============================] - 34s 676us/sample - loss: 0.0044 - acc: 0.9987 - val_loss: 3.9633 - val_acc: 0.6671\n",
      "CNN Model saved at models\\keras_cifar10_model_5_filtersize.h1 \n",
      "10000/10000 [==============================] - 2s 186us/sample - loss: 3.9633 - acc: 0.6671\n",
      "50000/50000 [==============================] - 9s 173us/sample - loss: 5.4998e-04 - acc: 0.9999\n",
      "Train loss:  0.0005499783222366932\n",
      "Trian metric:  0.99992\n",
      "Test loss:  3.963273580932617\n",
      "Test accuracy: 0.6671\n",
      "{'loss': [1.8325382605743408, 1.541527308731079, 1.4281354339981078, 1.3424862430953979, 1.2710768517303468, 1.2141172325897216, 1.1653586669540406, 1.1245716942596435, 1.087740777053833, 1.0554267909240722, 1.025326852054596, 0.9975373909759522, 0.972445952167511, 0.9487740697288514, 0.925538109588623, 0.9031556045722962, 0.8849089021110534, 0.8644897199821472, 0.844239542388916, 0.8261533246803283, 0.8082532654476166, 0.7917596080780029, 0.7759871160697936, 0.7599120262145996, 0.7428161614608765, 0.7276116933250427, 0.7132873892593384, 0.7000901007080078, 0.6837192691230773, 0.67015820561409, 0.6567630659103394, 0.6432418190956116, 0.6308580113124848, 0.6167910284996033, 0.6044254606151581, 0.5929384576511383, 0.5795984586715698, 0.5689779315662384, 0.556903949098587, 0.5438784603023529, 0.5318907400512696, 0.521037619228363, 0.5112727592182159, 0.4995101864528656, 0.4870049412727356, 0.4770507605457306, 0.465903245677948, 0.4566468010377884, 0.4460696013259888, 0.43569850604057314, 0.4251147244119644, 0.4145769095611572, 0.4057347375011444, 0.396263050737381, 0.38706202298641207, 0.3767528771305084, 0.3674728178691864, 0.35704769656658175, 0.3488992771816254, 0.33836579548597334, 0.3315562910985947, 0.32085673768520356, 0.31269555798769, 0.3040996683168411, 0.2956180711007118, 0.2855433825349808, 0.27869434952020644, 0.26953766685724256, 0.262602362190485, 0.2550528386688232, 0.2467267487168312, 0.23840967582464218, 0.23010646959900857, 0.2229711262178421, 0.21494486820697783, 0.2077333609712124, 0.20185619148731232, 0.19500392366170882, 0.1862979157602787, 0.1811335975921154, 0.173885689766407, 0.16784169268071653, 0.16193672010838986, 0.1563509021818638, 0.14950977569758891, 0.14268877402722835, 0.13728442105025054, 0.13155407066047192, 0.126950370156765, 0.12184534660756588, 0.11578820733189583, 0.11206455062925816, 0.10716378969013692, 0.10306762842833996, 0.0974385315105319, 0.09368158081188797, 0.09033174919724464, 0.08540369865000248, 0.0819850079447031, 0.07811605470895767, 0.07554749077230692, 0.07216121024549008, 0.06778072069451213, 0.06430682462006808, 0.060512348199933765, 0.05853535416975617, 0.056553011423796415, 0.05438138292044401, 0.050728275252431634, 0.049048815656527876, 0.04745209912613034, 0.0448548441387713, 0.04266181652801111, 0.04108648472622037, 0.039529168797079475, 0.037912944561317566, 0.03542886157944798, 0.03567600445307791, 0.03214075446970761, 0.03165982097260654, 0.029898133671116083, 0.028497909549176692, 0.02833168393149972, 0.027164219565577807, 0.025359573826696725, 0.02544815870091319, 0.023895067207701504, 0.02365501571036875, 0.023170762192867695, 0.022454688231358304, 0.02158903357360512, 0.02066927480597049, 0.01974013765502721, 0.019202355119977147, 0.019149973504897208, 0.018770597220314666, 0.01811630757663399, 0.017258478724309242, 0.017137918044812978, 0.01681092802603729, 0.015769136598929763, 0.01622704603594728, 0.01599569086847827, 0.015538855270911008, 0.014684533112663775, 0.014049014399521983, 0.014330146805448458, 0.015003383332369849, 0.014523956384693738, 0.014087075774215627, 0.01422806872789748, 0.01354917950340081, 0.01352759925531689, 0.012767714154408314, 0.012932037276276388, 0.012109704839985353, 0.011675236477071886, 0.011288026482940186, 0.011259778352701106, 0.011182022124943323, 0.011063887567225612, 0.01120323116700165, 0.010540716648225206, 0.010624156432359014, 0.0111204021276196, 0.010264842024841346, 0.010085737752895802, 0.0104344220290659, 0.009762009826075519, 0.009125371723246062, 0.009877806161451154, 0.009582314862601925, 0.00986123372754897, 0.009327535754439887, 0.00896667548752972, 0.009816111548615154, 0.00980970461496705, 0.008603841794990004, 0.009627918787464732, 0.009044595220151823, 0.008280537174165947, 0.008362302877512993, 0.007356406272114254, 0.00923322666670865, 0.008445977261679945, 0.008447405897665594, 0.008574255762332469, 0.008290534911972063, 0.008122952455509222, 0.007443612642298103, 0.007928221292603049, 0.0077197269598051205, 0.007776816513160011, 0.007120603129954543, 0.007935962485789205, 0.008203782507084834, 0.007119898064618173, 0.006906202650788764, 0.007683100670343847, 0.0067370571413228756, 0.007110469679316739, 0.007602425522499397, 0.007173511136455927, 0.006668304143574205, 0.007027543653316097, 0.006847983929163019, 0.007631712254704908, 0.007023205097167593, 0.007244629056550475, 0.006869509245851368, 0.006086853341298993, 0.007115801223654562, 0.0065156307081713745, 0.0071075401281945234, 0.006387795438402536, 0.006354459313544794, 0.0070272586509776015, 0.004970894410808105, 0.006410065515386959, 0.005878185393583117, 0.006117227621930506, 0.006744663705962302, 0.0060672436250178725, 0.005914679579094009, 0.005520956053433256, 0.00589677683792147, 0.00597404277690046, 0.006077041290332854, 0.005962514136610116, 0.005872964037633864, 0.005789367335203788, 0.007092912134725193, 0.005316380666327605, 0.006174346479743108, 0.005590227297444871, 0.0055548534652021045, 0.006845936848255078, 0.005857484966809934, 0.0053477091921269315, 0.005208342570626774, 0.00571716078108082, 0.005466435986278848, 0.005456034763061362, 0.005160158850999833, 0.005365606636860976, 0.0053665691494004936, 0.005678306841695812, 0.005276744856605582, 0.005811158450119547, 0.005278145778327962, 0.006663850184779167, 0.005754447759361065, 0.0051297450805462, 0.004261407993688699, 0.005916650744632425, 0.00511820849830383, 0.004652128400057773, 0.004887733757102251, 0.004418507049222353, 0.005357312050382024, 0.005353724727778608, 0.005573692410592703, 0.004937308568181543, 0.00550895813890329, 0.004578098006685795, 0.005360431942899304, 0.004603474959808737, 0.004414376886047903, 0.004538037052606669, 0.004512576023571337, 0.005392197026411714, 0.004493478794027942, 0.004683900142857074, 0.004332775310132129, 0.005184725555330005, 0.004245991539158058, 0.004174150521171104, 0.0037075850123886992, 0.004129563033830691, 0.005181276728503745, 0.004200351562239994, 0.0038157583099705334, 0.0050558799821782486, 0.00465670638708958, 0.00476763186583601, 0.004647489651865016, 0.004796525588010008, 0.003964823047963491, 0.0035665493708002213, 0.004038896515977995, 0.0042329552768065335, 0.004115014810850189, 0.004435908441838747, 0.004681740069290281, 0.0036396337862957626, 0.003620634315514253, 0.004725512443406624, 0.0043571849848229975, 0.0038002323157246337, 0.004365820176123452], 'acc': [0.33592, 0.44148, 0.48788, 0.52094, 0.5499, 0.5704, 0.59006, 0.60648, 0.62112, 0.6323, 0.64076, 0.65096, 0.65966, 0.67014, 0.6783, 0.68536, 0.69252, 0.69976, 0.70518, 0.7143, 0.71896, 0.72422, 0.7324, 0.73686, 0.74356, 0.75, 0.75456, 0.75816, 0.7651, 0.7692, 0.77382, 0.77802, 0.78472, 0.7898, 0.79364, 0.79884, 0.8027, 0.80526, 0.80966, 0.81464, 0.81848, 0.82412, 0.82518, 0.8317, 0.83648, 0.83824, 0.841, 0.84556, 0.84948, 0.85296, 0.85626, 0.85952, 0.86264, 0.86632, 0.87012, 0.8745, 0.87614, 0.88066, 0.88344, 0.88662, 0.88958, 0.8934, 0.89598, 0.89908, 0.90214, 0.90476, 0.90788, 0.9116, 0.91364, 0.9169, 0.91866, 0.92236, 0.92536, 0.92764, 0.93046, 0.93342, 0.93504, 0.9373, 0.9404, 0.94206, 0.9454, 0.94852, 0.94916, 0.95082, 0.95268, 0.9559, 0.95746, 0.95966, 0.96054, 0.96216, 0.96494, 0.96598, 0.96808, 0.9688, 0.9715, 0.97284, 0.97344, 0.97474, 0.97602, 0.9771, 0.97802, 0.97934, 0.98068, 0.98144, 0.98314, 0.98344, 0.984, 0.98514, 0.98566, 0.9865, 0.98662, 0.98734, 0.98868, 0.98876, 0.98924, 0.9893, 0.99056, 0.99028, 0.9922, 0.99214, 0.9921, 0.9927, 0.9927, 0.99222, 0.99316, 0.99326, 0.99364, 0.99366, 0.99336, 0.99368, 0.99392, 0.99462, 0.99484, 0.9947, 0.9951, 0.99496, 0.9948, 0.9954, 0.99492, 0.99546, 0.9957, 0.99554, 0.99528, 0.9954, 0.99612, 0.99634, 0.9965, 0.99546, 0.9958, 0.99594, 0.99596, 0.99624, 0.9963, 0.99626, 0.99632, 0.99664, 0.99664, 0.99688, 0.99682, 0.9967, 0.99648, 0.99678, 0.99704, 0.99706, 0.99678, 0.99706, 0.997, 0.99694, 0.99708, 0.9974, 0.99738, 0.99738, 0.99712, 0.99724, 0.99734, 0.99682, 0.99714, 0.99736, 0.99696, 0.9974, 0.99758, 0.99756, 0.99792, 0.99734, 0.99746, 0.9974, 0.99738, 0.99738, 0.99754, 0.99792, 0.99762, 0.99756, 0.99768, 0.9978, 0.9974, 0.99764, 0.99764, 0.99788, 0.99772, 0.99794, 0.99796, 0.9977, 0.99784, 0.99804, 0.99798, 0.998, 0.99766, 0.99796, 0.99778, 0.99784, 0.99836, 0.99802, 0.99816, 0.9978, 0.99806, 0.99786, 0.9979, 0.99852, 0.998, 0.99828, 0.99822, 0.99778, 0.99812, 0.99822, 0.99816, 0.99816, 0.9983, 0.99798, 0.99824, 0.99826, 0.99826, 0.998, 0.99832, 0.99814, 0.9985, 0.99814, 0.99808, 0.99816, 0.99862, 0.99826, 0.99838, 0.99816, 0.99838, 0.9985, 0.99828, 0.99838, 0.99816, 0.99838, 0.9981, 0.9987, 0.99792, 0.99834, 0.9983, 0.9986, 0.99828, 0.99838, 0.99856, 0.99852, 0.99862, 0.99852, 0.9984, 0.99848, 0.99884, 0.99836, 0.99854, 0.99852, 0.99856, 0.99874, 0.9986, 0.99868, 0.99846, 0.99862, 0.99838, 0.99852, 0.99858, 0.99866, 0.99878, 0.99872, 0.99882, 0.99876, 0.9986, 0.9989, 0.99874, 0.9986, 0.99862, 0.99862, 0.9987, 0.99878, 0.99894, 0.99882, 0.99864, 0.9988, 0.99862, 0.99874, 0.99884, 0.99898, 0.99868, 0.9987, 0.99878, 0.9987], 'val_loss': [1.6303169738769532, 1.4929041826248168, 1.3916110759735107, 1.3285546030044555, 1.2891829191207886, 1.2581719898223878, 1.2293292236328126, 1.1873190134048461, 1.1153603982925415, 1.0785817850112915, 1.1663170640945435, 1.0956505336761475, 1.015075068473816, 1.0312347107887267, 1.0107903316497804, 1.0545075735092162, 1.0631267585754394, 1.0290985786437987, 0.9908027545928955, 1.012618070602417, 0.9670625533103943, 1.0066260513305665, 0.9520517660140991, 0.9337272344589234, 0.9522124091148376, 0.9660370910644531, 0.9855678097724915, 0.9497657362937927, 0.9526895545005798, 0.9847500736236572, 0.9449734846115112, 0.9703923719406128, 0.9252750805854797, 0.9835016929626464, 0.9604177371978759, 0.9556455696105957, 0.948742949295044, 0.9568720335960388, 0.9899707011222839, 0.9848345777511597, 0.9815180778503418, 0.9628056562423706, 0.9995575032234192, 0.9719820397853851, 1.0249427523612975, 1.0241619755744935, 1.058879910850525, 0.9915742864131928, 1.0698860536575316, 1.0523097689628602, 1.0920075646400451, 1.079780382823944, 1.0691359305381776, 1.0965038486480714, 1.0817190081596375, 1.1215997356891632, 1.1408963157653809, 1.1301909567832946, 1.1901807576179504, 1.2035710198402405, 1.1609905863285064, 1.265164062309265, 1.2078447032928468, 1.2409069228649139, 1.2418062631607056, 1.275277117061615, 1.2769590476989745, 1.2951054104804993, 1.3022883948802948, 1.345622871017456, 1.3539846904754638, 1.3795366411209107, 1.4268670897483826, 1.4015119047164917, 1.4398858002662658, 1.4741026742935182, 1.483464091014862, 1.5241938306808471, 1.6012306413650512, 1.5845229488372803, 1.580197532939911, 1.5820217015266418, 1.6130524107933044, 1.6636511498451232, 1.6806506795883178, 1.7240921100616455, 1.7215917555809022, 1.7947338582992554, 1.7845796335220336, 1.8175822719573975, 1.8560387140274048, 1.92104093375206, 1.8850284479141235, 1.9591624048233032, 1.9829132199287414, 1.9791750057220459, 2.0776856100082397, 2.0613923663139344, 2.1730632301330566, 2.1881636169433594, 2.1147783401489257, 2.1413197174072267, 2.2631725782394407, 2.2218701107025147, 2.2760476934432985, 2.2554054841041564, 2.3273568115234373, 2.338083947753906, 2.337917578125, 2.3672853903770448, 2.3835837688446047, 2.4271086753845217, 2.493767356109619, 2.4348334674835206, 2.4961415035247803, 2.5607408744812012, 2.5309238679885864, 2.5870978125572206, 2.722915799713135, 2.6599794034957887, 2.746840670967102, 2.673379197692871, 2.674497983932495, 2.732644513988495, 2.799895933532715, 2.722268257713318, 2.7817168243408203, 2.7887984552383425, 2.8169202352523803, 2.8885274503707885, 2.87178435382843, 2.951881665802002, 2.9094068083763123, 2.9456452421188355, 2.9234922855377197, 2.9402300870895384, 3.03655103225708, 2.997105037689209, 3.004467984008789, 2.9817788383483887, 3.048472294139862, 3.055653151512146, 3.034790615463257, 3.0661857944488524, 3.104996046066284, 3.1259758224487304, 3.074931499862671, 3.0854579740524293, 3.1590096638679506, 3.117150556755066, 3.14743190574646, 3.222213744163513, 3.1511947505950926, 3.1709278118133546, 3.1969566675186156, 3.3239787866592407, 3.199040247154236, 3.2169773128509522, 3.2220200914382935, 3.313518747329712, 3.264099691963196, 3.2667435789108277, 3.2549162372589113, 3.3521021114349363, 3.3235348308563233, 3.3318979873657226, 3.3371640607833863, 3.393805236053467, 3.3765715251922606, 3.385667288208008, 3.3259594415664675, 3.3600686500549317, 3.3915713569641115, 3.4378477895736697, 3.405248996734619, 3.4155457409858703, 3.4455216625213625, 3.436708978462219, 3.440651707077026, 3.453992811203003, 3.432775012779236, 3.4971935863494874, 3.551795761871338, 3.4552345722198488, 3.507659736442566, 3.4735464836120604, 3.528213646697998, 3.5924881912231443, 3.5187033489227293, 3.5032514114379882, 3.5406023349761964, 3.5065646980285643, 3.566465573310852, 3.5461649566650393, 3.6045550680160523, 3.5589669059753417, 3.7193805614471436, 3.579167690086365, 3.6219915830612184, 3.6545840560913088, 3.5910916816711427, 3.633764366722107, 3.593085012817383, 3.6355310279846194, 3.6251065292358398, 3.6889350456237793, 3.6672129550933836, 3.7341866744995116, 3.6670117027282716, 3.6521174692153933, 3.662025824737549, 3.696803923034668, 3.703506121826172, 3.6602561859130858, 3.6921554069519043, 3.6534552673339844, 3.6576863693237303, 3.679092115402222, 3.703278709793091, 3.7528782081604004, 3.708084797859192, 3.7110348503112793, 3.794243936538696, 3.7427997032165528, 3.730133835411072, 3.7335416648864745, 3.7515819326400757, 3.7432385789871216, 3.773599588775635, 3.7537282455444334, 3.74341051864624, 3.7841290084838866, 3.7492391633987427, 3.7643861404418946, 3.7639366718292235, 3.74764341468811, 3.770020392990112, 3.807944356918335, 3.773397517204285, 3.803356257820129, 3.806523729324341, 3.7925599100112914, 3.8808623065948487, 3.823872755241394, 3.861241864299774, 3.816374356842041, 3.796568943977356, 3.8331711444854735, 3.819118841934204, 3.9881917835235594, 3.8571674039840698, 3.84666912651062, 3.8399272979736327, 3.8293280712127684, 3.8628370723724363, 3.8662089107513427, 3.8207300121307375, 3.8474798290252687, 3.8273363561630247, 3.969843989753723, 3.8580169490814207, 3.864480424118042, 3.868517768096924, 3.8587838451385497, 3.864688518333435, 3.916846266555786, 3.9015448024749757, 3.891259090423584, 3.8787830806732178, 3.954292809677124, 3.953726787948608, 3.91868844871521, 3.90248888835907, 3.8770366092681883, 3.891166049385071, 3.914994289779663, 3.9263537368774415, 3.9048623443603514, 3.9207587198257445, 3.9022237232208252, 3.94842162361145, 3.9352886325836183, 3.9503703720092775, 3.9828357755661012, 3.958539842224121, 3.963149698638916, 3.9486460134506225, 3.9833910373687744, 3.9266347660064698, 3.9431381621718407, 3.9627624824523924, 3.9580992656707763, 3.942172893333435, 3.9774865530014036, 3.9571561419487, 3.9426006984710695, 3.9949054811477662, 3.9550370109558104, 4.024266918563843, 3.963273592376709], 'val_acc': [0.4168, 0.4669, 0.5084, 0.5257, 0.5387, 0.5613, 0.5656, 0.5904, 0.6132, 0.6262, 0.5917, 0.6195, 0.6456, 0.6425, 0.6476, 0.6366, 0.6284, 0.6432, 0.6556, 0.6524, 0.6634, 0.6513, 0.6707, 0.6803, 0.6779, 0.6721, 0.6703, 0.6756, 0.682, 0.6701, 0.6853, 0.6784, 0.6923, 0.68, 0.6855, 0.6884, 0.6915, 0.6934, 0.683, 0.6867, 0.6899, 0.6962, 0.6889, 0.6965, 0.6872, 0.6935, 0.6771, 0.7009, 0.6789, 0.6953, 0.6832, 0.6889, 0.6904, 0.6931, 0.6926, 0.6923, 0.6933, 0.6907, 0.6795, 0.6848, 0.6953, 0.6764, 0.6873, 0.6771, 0.6852, 0.6834, 0.6874, 0.6895, 0.6915, 0.6806, 0.6832, 0.6785, 0.676, 0.689, 0.6744, 0.6814, 0.686, 0.6774, 0.6751, 0.6789, 0.6855, 0.6786, 0.6802, 0.6773, 0.6769, 0.6789, 0.6795, 0.6754, 0.6777, 0.6784, 0.678, 0.6713, 0.6738, 0.6742, 0.6762, 0.6722, 0.6672, 0.6717, 0.6628, 0.6643, 0.6749, 0.6743, 0.6631, 0.6693, 0.6702, 0.6739, 0.6684, 0.6695, 0.6724, 0.6705, 0.6708, 0.6717, 0.6641, 0.6717, 0.6741, 0.6687, 0.667, 0.6714, 0.6532, 0.6687, 0.662, 0.6677, 0.6706, 0.6704, 0.665, 0.6713, 0.6721, 0.6705, 0.6668, 0.6641, 0.6664, 0.661, 0.6661, 0.6619, 0.6667, 0.6661, 0.6621, 0.6613, 0.6673, 0.6691, 0.6605, 0.6681, 0.668, 0.6699, 0.6657, 0.6653, 0.6693, 0.6651, 0.6641, 0.6665, 0.6673, 0.6633, 0.6679, 0.6681, 0.6688, 0.6597, 0.6666, 0.6684, 0.6709, 0.6582, 0.6709, 0.6693, 0.6681, 0.6643, 0.6695, 0.6657, 0.6689, 0.6629, 0.6694, 0.6636, 0.6698, 0.6694, 0.6665, 0.6644, 0.665, 0.6657, 0.6641, 0.6672, 0.6671, 0.6672, 0.6668, 0.6656, 0.6618, 0.6676, 0.6656, 0.6682, 0.6639, 0.661, 0.6672, 0.667, 0.6657, 0.6689, 0.6622, 0.6652, 0.6634, 0.6671, 0.657, 0.6662, 0.6606, 0.6642, 0.664, 0.662, 0.6641, 0.6656, 0.665, 0.664, 0.6632, 0.6599, 0.6654, 0.6685, 0.6681, 0.6648, 0.6641, 0.6672, 0.665, 0.6665, 0.663, 0.6659, 0.6671, 0.6616, 0.6648, 0.6636, 0.6567, 0.6647, 0.6651, 0.6648, 0.6616, 0.6644, 0.6653, 0.6654, 0.6672, 0.6625, 0.6683, 0.6658, 0.665, 0.6688, 0.667, 0.6636, 0.6661, 0.6668, 0.6644, 0.6647, 0.6605, 0.6637, 0.663, 0.6671, 0.6683, 0.6634, 0.6645, 0.6544, 0.6618, 0.6654, 0.6643, 0.6646, 0.6658, 0.6634, 0.6673, 0.6641, 0.6671, 0.6565, 0.6649, 0.6649, 0.6671, 0.6673, 0.6665, 0.6626, 0.6635, 0.665, 0.6646, 0.662, 0.6625, 0.6639, 0.666, 0.6672, 0.6651, 0.6663, 0.6654, 0.6671, 0.6666, 0.6656, 0.6634, 0.6672, 0.6654, 0.6618, 0.6632, 0.6662, 0.6688, 0.6623, 0.6662, 0.6693, 0.6643, 0.6654, 0.6657, 0.6649, 0.6648, 0.6658, 0.6663, 0.6661, 0.6628, 0.6671]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# initialization of optimizer \n",
    "opt = keras.optimizers.RMSprop(learning_rate = 0.0001,decay = 1e-6)\n",
    "\n",
    "# train the model by optimizer\n",
    "cnn_model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = opt,\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "train_set = train_set.astype('float32')\n",
    "test_set = test_set.astype('float32') \n",
    "\n",
    "train_set /= 255 \n",
    "test_set /= 255 \n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    cnn_history = cnn_model.fit(train_set, train_label,\n",
    "              batch_size=batch_size,\n",
    "              epochs=num_epochs,\n",
    "              validation_data=(test_set, test_label),\n",
    "              shuffle=True)\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "# save model and weights \n",
    "if not os.path.isdir(model_dir): \n",
    "    os.makedirs(model_dir) \n",
    "model_path = os.path.join(model_dir,model_filename)\n",
    "cnn_model.save(model_path)\n",
    "print(\"CNN Model saved at %s \" % model_path)\n",
    "\n",
    "# Score trained model \n",
    "\n",
    "test_loss_value, test_metric_value = cnn_model.evaluate(test_set,test_label,verbose =1 )\n",
    "train_loss_value, train_metric_value = cnn_model.evaluate(train_set,train_label,verbose =1)\n",
    "\n",
    "\n",
    "print(\"Train loss: \", train_loss_value) \n",
    "print(\"Trian metric: \", train_metric_value)\n",
    "\n",
    "print(\"Test loss: \", test_loss_value)\n",
    "print(\"Test accuracy:\", test_metric_value)\n",
    "print(cnn_history.history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max test accuracy is  0.7009\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# get history data\n",
    "epoth_x = np.linspace(0, 10, num_epochs, endpoint=True)\n",
    "train_loss = cnn_history.history['loss']\n",
    "train_accuracy = cnn_history.history['acc']\n",
    "test_loss = cnn_history.history['val_loss']\n",
    "test_accuracy = cnn_history.history['val_acc']\n",
    "\n",
    "# plot train loss and accuracy\n",
    "plt.figure() \n",
    "plt.plot(epoth_x, train_loss,label = 'train loss')\n",
    "plt.plot(epoth_x,train_accuracy,label = 'train accuracy')\n",
    "plt.title(\"train loss and train accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# plot test loss and accuracy\n",
    "plt.figure() \n",
    "plt.plot(epoth_x, test_loss, label = 'test loss')\n",
    "plt.plot(epoth_x,test_accuracy, label = 'test accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"test loss and test accuracy\")\n",
    "\n",
    "# get max test accuracy and \n",
    "\n",
    "print(\"The max test accuracy is \",max(test_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
