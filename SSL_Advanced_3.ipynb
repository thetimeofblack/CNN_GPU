{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from skimage.util import view_as_windows\n",
    "from tensorflow.keras.datasets import cifar10 \n",
    "from pixelhop2 import * \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from llsr import LLSR as myLLSR\n",
    "from lag import * \n",
    "from tensorflow.keras.datasets import cifar10 \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot \n",
    "from matplotlib import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from cross_entropy import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "# get data \n",
    "(train_set,train_label),(test_set,test_label) = cifar10.load_data() \n",
    "# class number \n",
    "\n",
    "print(train_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_balance_data_set_split(data_set,label_set,nClasses,split_coef):\n",
    "    # test balance data set \n",
    "    nClasses = 10 \n",
    "    data_set_split = []\n",
    "    label_set_split = []\n",
    "    print(train_label==9)\n",
    "    print(np.where(label_set==9)[0])\n",
    "    for i in range(nClasses):\n",
    "        data_set_class = data_set[np.where(label_set==i)[0],:,:,:]\n",
    "        data_set_class_split,_,label_set_class_split, _ = train_test_split(data_set_class,label_set[train_label==i],train_size = split_coef)\n",
    "        data_set_split.append(data_set_class_split)\n",
    "        label_set_split.append(label_set_class_split)\n",
    "    data_set_split = np.concatenate(data_set_split,axis = 0 )\n",
    "    label_set_split = np.concatenate(label_set_split,axis = 0)\n",
    "    print(data_set_split.shape)\n",
    "    return data_set_split,label_set_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test balance data set \n",
    "nClasses = 10 \n",
    "# train_data_split = []\n",
    "# train_label_split = []\n",
    "# print(train_label==9)\n",
    "# print(np.where(train_label==9)[0])\n",
    "# for i in range(nClasses):\n",
    "#     train_data_class = train_set[np.where(train_label==i)[0],:,:,:]\n",
    "#     train_data_class_split,_,train_label_class_split, _ = train_test_split(train_data_class,train_label[train_label==i],train_size = 0.2)\n",
    "#     train_data_split.append(train_data_class_split)\n",
    "#     train_label_split.append(train_label_class_split)\n",
    "# train_data_split = np.concatenate(train_data_split,axis = 0 )\n",
    "# train_label_split = np.concatenate(train_label_split,axis = 0)\n",
    "# print(train_data_split.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shrink and concat function \n",
    "# example callback function for collecting patches and its inverse\n",
    "def Shrink(X, shrinkArg):\n",
    "    win = shrinkArg['filterwin']\n",
    "    stride = shrinkArg['stride']\n",
    "    poolwin = shrinkArg['poolwin']\n",
    "    depth = shrinkArg['depth']\n",
    "   \n",
    "    # print(\"Shrink function\")\n",
    "    print(\"shape of original X:\",X.shape)\n",
    "    X = view_as_windows(X, (1,win,win,1), (1,stride,stride,1))\n",
    "    # print(\"shape of windowed X: \",X.shape)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], -1)\n",
    "    print(X.shape)\n",
    "    return X\n",
    "\n",
    "def nonShrink(X, shrinkArg) : \n",
    "    return X\n",
    "# example callback function for how to concate features from different hops\n",
    "def Concat(output, concatArg):\n",
    "    #print(\"the shape of final output is \", len(output))\n",
    "#    for i in range(len(output)-1):\n",
    "    #for i in range(len(output)):\n",
    "     #   output[i].reshape(output[i].shape[0],-1)\n",
    "    S = output[0].shape\n",
    "    for i in range(len(output)):\n",
    "        output[i] = output[i].reshape(S[0],-1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test shrink and concat function \n",
    "X = np.array([ [ [ [1, 2],[ 3, 4 ] ], [[ 5, 6  ],[ 7, 8 ]] ] , \n",
    "               [ [[ 9, 10 ],[ 11, 12  ]] , [[ 13, 14 ],[ 15 ,16 ] ]  ]  ])\n",
    "\n",
    "# print(X.shape)\n",
    "shrinkArgs = [{'func':Shrink,'poolwin':2,'method':np.max,'filterwin':5,'stride':1,'depth':1}, \n",
    "              {'func':Shrink,'poolwin':2,'method':np.mean,'filterwin':5,'stride':1,'depth':2},\n",
    "              {'func':Shrink,'poolwin':2,'method':np.mean,'filterwin':4,'stride':1,'depth':3}] \n",
    "# Shrink(X,shrinkArgs[0])\n",
    "concatArg = {'func':Concat}\n",
    "# print(X.shape)\n",
    "# print(X)\n",
    "# print(train_set.shape)\n",
    "# train_set_shrunken = Shrink(train_set,shrinkArgs[0])\n",
    "# train_set_shrunken_2 = Shrink(train_set,shrinkArgs[1])\n",
    "# con = [] \n",
    "# con.append(train_set_shrunken)\n",
    "# con.append(train_set_shrunken_2)\n",
    "# print(np.concatenate(con,axis=-1).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaabArgs = [{'num_AC_kernels':-1, 'needBias':False, 'useDC':True, 'batch':None, 'cw':False}, \n",
    "            {'num_AC_kernels':-1, 'needBias':True, 'useDC':True, 'batch':None, 'cw':True, 'stride':1,'win':3},\n",
    "            {'num_AC_kernels':-1, 'needBias':True, 'useDC':True, 'batch':None, 'cw':True, 'stride':1,'win':3},\n",
    "            {'num_AC_kernels':-1, 'needBias':True, 'useDC':True, 'batch':None, 'cw':True, 'stride':1,'win':3}]\n",
    "shrinkArgs = [{'func':Shrink   , 'poolwin':2, 'stride':1 ,'filterwin':5,'depth':1,'method':np.max}, \n",
    "              {'func':Shrink   , 'poolwin':2, 'stride':1 ,'filterwin':5,'depth':2,'method':np.mean},\n",
    "              {'func':Shrink   , 'poolwin':1, 'stride':1 ,'filterwin':3,'depth':3,'method':np.mean},]\n",
    "concatArg = {'func':Concat,'depth':3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixelhop2 fit\n",
      "shape of original X: (50000, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12414\\Anaconda3\\lib\\site-packages\\skimage\\util\\shape.py:246: RuntimeWarning: Cannot provide views on a non-contiguous input array without copying.\n",
      "  warn(RuntimeWarning(\"Cannot provide views on a non-contiguous input \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28, 75)\n",
      "fit finish\n",
      "batch : 0\n",
      "batch : 1\n",
      "batch : 2\n",
      "batch : 3\n",
      "batch : 4\n",
      "current layer 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'method'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-abb7a6985f4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpixelhop_unit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPixelhop2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTH1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTH2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSaabArgs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSaabArgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshrinkArgs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshrinkArgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcatArg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconcatArg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodulus1_st\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpixelhop_unit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodulus1_et\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodulus1_training_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodulus1_et\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmodulus1_st\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\EE 569 Image processing\\EE569-Digital-Signal-Processing\\hw6\\SSLv2\\pixelhop2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pixelhop2 fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[1;31m#X = self.select_(X)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m#return self.concatArg['func'](X, self.concatArg)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\EE 569 Image processing\\EE569-Digital-Signal-Processing\\hw6\\SSLv2\\cwSaab.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;31m#        output, DC = [], []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcwSaab_1_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;31m#        output.append(X)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;31m#        DC.append(dc)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\EE 569 Image processing\\EE569-Digital-Signal-Processing\\hw6\\SSLv2\\cwSaab.py\u001b[0m in \u001b[0;36mcwSaab_1_layer\u001b[1;34m(self, X, train)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                 \u001b[0msaab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaabTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m                 \u001b[0msaab_cur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                 \u001b[0meng\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnergy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\EE 569 Image processing\\EE569-Digital-Signal-Processing\\hw6\\SSLv2\\cwSaab.py\u001b[0m in \u001b[0;36mSaabTransform\u001b[1;34m(self, X, saab, train, layer)\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mtransformed_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mview_as_windows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformed_tmp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpoolwin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpoolwin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpoolwin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpoolwin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mtransformed_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformed_tmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformed_tmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtransformed_tmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtransformed_tmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtransformed_tmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                 \u001b[0mtransformed_tmp\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mshrinkArg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'method'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformed_tmp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m                 \u001b[0mpooled_transformed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformed_tmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mtransformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpooled_transformed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'method'"
     ]
    }
   ],
   "source": [
    "pixelhop_unit = Pixelhop2(depth=3, TH1=0.001, TH2=0.0001, SaabArgs=SaabArgs, shrinkArgs=shrinkArgs, concatArg=concatArg)\n",
    "modulus1_st = time.time()\n",
    "pixelhop_unit.fit(train_set)\n",
    "modulus1_et = time.time() \n",
    "modulus1_training_time = modulus1_et - modulus1_st \n",
    "print(modulus1_training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modulus2_st = time.time()\n",
    "train_pixelhop_tran_set =  pixelhop_unit.transform(train_set)\n",
    "\n",
    "# train_data_pixelhop = np.concatenate(output,axis= -1)\n",
    "infer_time_m1_st = time.time()\n",
    "test_pixelhop_tran_set = pixelhop_unit.transform(test_set)\n",
    "infer_time_m1_ed = time.time()\n",
    "infer_time_m1 = infer_time_m1_ed - infer_time_m1_st\n",
    "# test_data_pixelhop = np.concatenate(output,axis =-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection based on cross entropy \n",
    "N_C = [0.6,0.7,0.8 ] \n",
    "num_cluster = 10\n",
    "num_clusters_parm = [] \n",
    "infer_time_m2_cross = 0 \n",
    "for layer in range(len(train_pixelhop_tran_set)):\n",
    "    cross_entropy = Cross_Entropy(num_class=10, num_bin=num_cluster)\n",
    "    train_pixelhop_tran = train_pixelhop_tran_set[layer]\n",
    "    num_features = int(train_pixelhop_tran.shape[-1]*N_C[layer])\n",
    "    feature_cross_entropy = cross_entropy.KMeans_Cross_Entropy(train_pixelhop_tran, train_label)\n",
    "    feature_select = np.argsort(feature_cross_entropy)[:num_features]  \n",
    "    train_pixelhop_tran_set[layer] = train_pixelhop_tran_set[layer][:,feature_select]\n",
    "    infer_time_m2_cross_st = time.time()\n",
    "    test_pixelhop_tran_set[layer] = test_pixelhop_tran_set[layer][:,feature_select]\n",
    "    infer_time_m2_cross_ed = time.time()\n",
    "    infer_time_m2_cross+=infer_time_m2_cross_ed-infer_time_m2_cross_st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_time_m2_lag = 0 \n",
    "for i in range(10):\n",
    "    num_clusters_parm.append(num_cluster)\n",
    "train_lag_tran_set = [] \n",
    "test_lag_tran_set = []\n",
    "for layer in range(len(train_pixelhop_tran_set)):\n",
    "    lag = LAG(encode='distance', num_clusters= num_clusters_parm, alpha=7, learner=myLLSR(onehot=False))  \n",
    "    print(train_pixelhop_tran_set[layer].shape)\n",
    "    lag.fit(train_pixelhop_tran_set[layer],train_label)\n",
    "    train_lag_tran = lag.transform(train_pixelhop_tran_set[layer])\n",
    "    train_lag_tran_set.append(train_lag_tran)\n",
    "    infer_time_m2_lag_st = time.time()\n",
    "    test_lag_tran = lag.transform(test_pixelhop_tran_set[layer])\n",
    "    test_lag_tran_set.append(test_lag_tran)\n",
    "    infer_time_m2_lag_ed = time.time()\n",
    "    infer_time_m2_lag +=  infer_time_m2_lag_ed - infer_time_m2_lag_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection based on cross entropy \n",
    "# N_C = 0.5\n",
    "\n",
    "# for layer in range(len(train_pixelhop_tran_set)):\n",
    " #  cross_entropy = Cross_Entropy(num_class=10, num_bin=num_cluster)\n",
    " #  train_lag_tran = train_lag_tran_set[layer]\n",
    " #  feature_cross_entropy = np.zeros(train_lag_tran.shape[-1])\n",
    " #  num_features = int(train_lag_tran.shape[-1]*N_C)\n",
    " #  for k in range(train_lag_tran.shape[-1]):\n",
    " #      feature_cross_entropy[k] = cross_entropy.KMeans_Cross_Entropy(train_lag_tran[:,k].reshape(-1,1), train_label)\n",
    " #  feature_select = np.argsort(feature_cross_entropy)[:num_features]  \n",
    " #  train_lag_tran_set[layer] = train_lag_tran_set[layer][:,feature_select]\n",
    " #  test_lag_tran_set[layer] = test_lag_tran_set[layer][:,feature_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_lag_tran_set[0].shape)\n",
    "train_tran_classifier = np.concatenate(train_lag_tran_set,-1)\n",
    "test_tran_classifier = np.concatenate(test_lag_tran_set,-1)\n",
    "modulus2_et = time.time()\n",
    "modulus2_training_time = modulus2_et - modulus2_st \n",
    "print(\"modulus2 training time\", modulus2_training_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm_classifier = SVC(C =1,gamma = 10, kernel='rbf' )\n",
    "#svm_classifier.fit(train_tran_classifier,train_label)\n",
    "modulus3_st = time.time()\n",
    "random_forest = RandomForestClassifier(n_estimators=600, criterion='gini')\n",
    "random_forest.fit(train_tran_classifier,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = random_forest.predict(train_tran_classifier)\n",
    "infer_time_m3_classifier = 0 \n",
    "infer_time_m3_classifier_st = time.time()\n",
    "test_pred = random_forest.predict(test_tran_classifier)\n",
    "infer_time_m3_classifier_ed = time.time()\n",
    "infer_time_m3_classifier = infer_time_m3_classifier_ed - infer_time_m3_classifier_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(train_label,train_pred))\n",
    "print(accuracy_score(test_label,test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_infer_time_test = infer_time_m1 + infer_time_m2_cross + infer_time_m2_lag + infer_time_m3_classifier\n",
    "print(\"total inference time for test data set\", total_infer_time_test)\n",
    "train_confusion_matrix = confusion_matrix(train_label, train_pred)\n",
    "test_confusion_matrix = confusion_matrix(test_label,test_pred)\n",
    "modulus3_et = time.time() \n",
    "modulus3_training_time = modulus3_et - modulus3_st \n",
    "print(\"modulus3 training time\", modulus3_training_time)\n",
    "pyplot.figure()\n",
    "pyplot.imshow(train_confusion_matrix)\n",
    "pyplot.figure()\n",
    "pyplot.imshow(test_confusion_matrix)\n",
    "print(\"------- DONE -------\\n\")\n",
    "print(train_confusion_matrix)\n",
    "print(test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
